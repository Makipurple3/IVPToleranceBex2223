---
title: "Testing for Tolerance in a Box Experiment in Wild Vervet Monkeys - M.AungKyaw - 2022-2023"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: 6
    toc_float:
      collapsed: no
  word_document:
    toc: yes
    toc_depth: 6
  pdf_document:
    toc: yes
    toc_depth: 6
date: "`r format(Sys.time(), '%B %d, %Y %H:%M')`"
header-includes:
  - \usepackage[utf8]{inputenc}
  - \usepackage{amssymb}
  - \usepackage{textcomp}
  - \usepackage[T1]{fontenc}
  - \usepackage{underscore}
  - \usepackage{newunicodechar}
  - \newunicodechar{≠}{$\neq$}
---

```{r setup, include=FALSE}
# Set global knitr options
knitr::opts_chunk$set(echo = TRUE)
```

<center>
    <img src="/Users/maki/Desktop/Master Thesis/BEX 2223 Master Thesis Maung Kyaw/BEX Visuals/Minimalist-vervet-box-logo.png" alt="Minimalist Vervet Box Logo" style="width: 50%; height: auto;"/>
</center>



# Introduction
```{r Cleaning of environement, echo=FALSE}
# Clear the environment 
rm(list = ls())
```

# 0.Opening the data
### Loading data

```{r LoadData, include=FALSE}

# Load knitr for  markdown outputs
library(knitr)

##Load pander for better presentation of the outputs
library(pander)

##Load dplyr for better manipulation of the data
library(dplyr)

# Load readxl package to import the data
library("readxl")

# Load the openxlsx package to export data to xlsx file
library(openxlsx)

# Load Lubridate for better date and time manipulation
library(lubridate)

# Load Stringr for easier data manipulation and cleaning
library(stringr)

# Load GGPlot for graphics and representations of the dataset
library(ggplot2)

# Load TidyR for better data handling
library(tidyr)

# Read xlsx files
Boxex <- read_xls("/Users/maki/Desktop/Master Thesis/BEX 2223 Master Thesis MAung Kyaw/Makipurple3/Box Experiments.xls")

``` 

* First I downloaded the **knitr package** to create outputs as html, pdf or word files when knitting my r markdown file. I also loaded the **pander** package for better presentation
* The **dplyr** package was installed for better manipulation of the data as filtering or creating new variables and **lubridate** for a better manipulation of dates and time
* Then, I installed the **readxl package** to import my dataset which is called **Box Experiments.xls**
* This dataset contains information related to my master thesis project. I used cyber tracker in order to record the behaviors of dyads of Vervet monkeys in a box experiment on tolerance from September 2022 to September 2023

# 1.Explore the data

### Description of the initial datset - "Boxex"

```{r View and Glimpse of Boxex, echo=FALSE}

# First View of my datset using View(Boxex)> Line removed for knitting


#GLimpse function to see the summary and  the structure
cat("Glimpse of the Box Experiment dataset:\n\n")
glimpse(Boxex)

#Head of Boxex for sample view of the data
head(Boxex)



```



* I am now using the **View** function to have a sight on the entire dataset and **glimpse** to display a summary of my dataset
* I have **20 variables** (here columns) and **2795 trials** (here rows)

* I will now make a brief summary of each variables and their use before creating a new dataframe (df) with my variables of interest that I will call **Bex**

* The highlighted variables are the ones I will use for **Bex**. I will then **clean the data**  before heading to the **statistical analysis** and the **interpretation of the results**


#### Variables of Boxex

* **Date**               :
    "Date" is in a **POSIXct** format which is appropriate for the display of time 

    * I want to use the date to know **how many sessions** have been done with each dyads in my experiment. 
    * I will create a variable called **Session** where **1 session = 1 day**
    * The data has values from the **14th of September 2022** until the **13th of September 2023**
    * I may consider separating the **12 months** of data in **4 seasons** to make a preliminary check of a potential effect of seasonality. Nevertheless since we did not use any tools to measure the weather,         temperature, humidity or food availability (also related to seasonality and weather). Categorizing my data in 4 without having further data would then be quite arbitrary. If I end up doing it in my          report, it will be done without any intention to include it in my scientific analysis nor my scientific report .
    

    
* **Time**                  : 
     "Time is coded" in a **POSIXct** format 
     
    * I do not plan to use this variable but we can see that "Time" has the correct hours displayed with a date which is incorrect. 
    * (In the case I wanted to observe **when the trials occurred during the day** as time may have an influence on their behavior (**Isbell & Young 1993**)) I would need to correct the incorrect display of the date in the dataset.
    * This variable could also be useful to see when  the **seasonal effect** took place as we only went in the morning during summer because of the heat while we went later and for longer times in the          field to do the box experiment in winter 
    * For now, the values in "Time" are all on the same (wrong) day which is the **31st  of December** 
    * Note: I first did not intend to keep **Time** in Bex but I needed this variable to see the order of the trails within a day. I finally decided to keep it.
    
* Data                   : chr 
    "Data" is coded as **character**
    * It describes **the type of data** being recorded in the software **cybertracker**. We installed the software on tablets to record the different behaviors of vervet monkeys in our research center
    * In our case, my data was recorded in cybertracker as **Box Experiment** as we created a form specifically for this experiment
    * For this reason we can remove this column since the information it contains is unecessary and redundant
      
* Group             : chr 
    The data is coded in r as a **character**
    * It describes the **group of monkey** in which we did the trial
    * I will keep this column to see the amount of trials that we did in the 3 group of monkeys which are Baie-Dankie **(BD)**, Ankhase **(AK)**, and Noha **(NH)**
      
* GPSS                   : num 
    "GPSS" is coded as **numerical**
    * It gives the **south coordinates** in which we started the experiment
    * I do not plan to use coordinates nor look at locations so I will remove this acolumn
    
* GPSE                   : num 
    "GPSE" is coded in as **numerical**
    * It gives the **east coordinates** in which we started the experiment
    * I do not plan to use coordinates nor look at locations so I will remove this column
  
* **MaleID**             : chr 
    "MaleID" is coded as **character**
    * It indicates the **name of the male involved in the trial**
    * I plan to use this to see how factors related to the individual may influence the            experiment (age, sex, rank)
    * It will also help me see which behaviour was displayed by each individuals (here males)
  
  
* **FemaleID**           : chr
    "FemaleID" is coded as **character**
    * It indicates the **name of the female involved in the trial**
    * I plan to use this variable in the same way as "Male ID"
    * It will also help me see which behaviour was displayed by each individuals (here females)
    
* **Male placement corn**: dbl
    "Male placement corn is coded in r as **double**
    * It gives the **amount of corn given to the male of the dyad before the trials**
    * Within a session it happened that we gave more placement corn to attract the monkeys again to the boxes. This lead to an update of the number in the same session. The number found at the end of the         session is the total placement corn an individual has received
    * I will fuse this column with **male corn** as the data has been separated between these two variables. This is due to a mistake when creating the original box experiment form in cybertracker
    
    * This variable could be related to the level of motivation of a monkey but as it is not directly related to my hypothesis I may not use this column. I will re-consider the use of this column later on
    * In regards of this possibility I will change the format of the variable to numerical 
  
* **MaleCorn**           : dbl
    "MaleCorn" is coded in r as **double**
    * It gives the same information as in **male placement corn**
    * I will import the values from "male placement corn" into this one
    * I will change the format of the variable to numerical 
    
    
* **FemaleCorn**         : dbl
    The data is coded in r as **double**
    * It gives the **amount of corn given to the female of the dyad before the trials**
    * It works in the same way as "male placement corn"/"MaleCORN"
    * I will change the format of the variable to numerical 
  
  
* **DyadDistance**       : chr 
    The data is coded in r as **character**
    * It gives the **distance for each trial** that we have done with the dyads. 
    * The trial number 1 for each dyad was at 5 meters. 
    * The maximum was around 10 m while the minimum is 0
    * We will have to remove the "m" for meters in order to have a numerical variable instead of character
    * Also, since the very first trials per dyad can be considered as a kind of learning phase, i may remove the **15 first trials** that were made for each dyad
  
* **DyadResponse**       : chr 
    The data is coded in r as **character**
    * It indicated which **behaviour was produced by the dyad's during each trial**
    * The different behaviours were: **Distracted**, **Female aggress male**, **Male aggress female**, **Intrusion**, **Loosing interest**, **Not approaching**, **Tolerance** and **Other**
    * I will change the columns associated to each behavior (i.e. Response) of  **DyadResponse**    into dichotomic variables in order to see the frequency of each behaviour
    * This will allow me to see which behavior occurred more ,and behavioural differences could be found between dyads 
    * As multiple response could occur within the same trial, multiple behaviors can be found in a single cell. I will create a  hierarchy to reduce the amount of behaviors assigned to each trial (if  there     is more than one). This will also be complemented with the information found in the column **remarks**
      1. correct any mistakes (ex. if tolerance and aggression are together aggression>tolerance)
      2. assign as few labels per trial 
      3. get a better View and understanding of the data and the most common behaviours produced by each dyad
      4. create variables that can complement the behaviour found (ex. not approaching + looks at partner would be looks at partner + a new variable called hesistant to see when the did not come but look at         the other individual / )
      
    * Projection of the hierarchy (changes will be made)
      - Create a table with each combination existing
      
      - Decide what is more important
      - Ex:
        - Aggression > Tolerance
        - Tolerance > Not approaching -> Create a variable called hesistant in         addtion to the tolerance count to see frequency of tolerance                 behaviour that happened after > 1min
        - Tolerance > Loosing interest
        - Tolerance > Intrusion
        - Not approaching = looking box but not coming while Loosing interest           = not paying attention to the box
        - Intrusion > Loosing interest
        - Intrusion > Not approaching
        - Not approaching > Looks at partner
        - We can code every look at partner as no approaching and keep the             count of looks at partner as additional information
        - Not approaching >?> Loosing interest ? !!
        - Define distracted
        - Not approaching > Distracted
        - Aggression > Not approaching
        - Other > Look case by case and categorize depending of behavior
        - Remarks may be used for the same reason
        
  
* **OtherResponse**      : chr 
    "The data"OtherResponse" is coded as **character**
    * It describes **any behaviour that is different from the ones found in Dyad Response**     (meaning ≠ tolerance, aggression, intrusion, loosing interest, not approaching, distracted, looks at partner that where categorized as **other**)
    * I will have to look at every **OtherResponse** and rename each entry in one of the response already if existing. I will proceed case by case.
    * If I want to do an intermediate manipulation I may rename every NA in "OtherResponse" into **Response** to see the amount of case to treat and how many occurrences seem to not fit in the categories of  "DyadResponse"
    
* **Audience**      : chr 
    "Audience" is in r as **character**
    * It gives the **names of the individuals in the audience**
    * I would like to use it to see the **amount of audience (big vs small)** and the **dominance level of the audience (high vs low)** 
    * I will create a variable called **NAudience** to see hoy many individuals are in the audience for each trial
    * After calculating the elo ratings of the individuals using another dataset (Life history), I will create a dichotomic variable called **RankAudience** to see effects related to rank with the effect of audience
    
* **IDIndividual1**      : chr 
    "IDIndividual1" is coded in r as **character**
    * It gives the **names of the individuals that did not approach, showed aggression, got distracted or lost interest** during a trial
    * I will have to look at it to see how often these behaviors occurred
    * I will consider how to use this variable during the cleaning of the data
    
* **IntruderID**         : chr 
    "IndtruderID" is coded as **character**
    * It gives the **name of the individual that intruded the experiment during a trial**
    * Intrusion could mean, invade the space of the experiment and interact with one of our individual, steal the food, show agnostic behavior, stand in very close proximity of the dyad's individuals
    
* **Remarks**            : chr 
    The data is coded in r as **character**
    * It gives either additional information concerning the experiment when unusual behaviors occurred , mistakes that needed to be corrected or details that we wanted to record in        case we would need them
    
* Observers               :chr
    The data is coded in r as **character**
    * It gives the **names of the observers during the experiment**
    * We will not use this data as we do not look at the effect that an experimenter would have on the monkeys
    * (Should I still look at an effect of the amount of experimenter?...maybe better for detailled analysis of our study)
    
* DeviceID             :chr
    "The data "DeviceID" is coded in r as **character**
    * It gives the **name of the device/tablet** used to record the data during the experiment
    * We will not use this data either
    
    

# 2. Treating missing data

## 2.1. Creating a new dataframe - Bex
* Since I do not want to work with the whole dataset, I'm gonna select the variables of interest using the function **select**

* I will keep Time, Date, Group, MaleID, FemaleID, MaleCorn, Male placement corn, FemaleCorn, DyadDistance, DyadResponse, OtherResponse, Audience, IDIndividual1, IntruderID, Remarks

```{r Bex Df, echo=FALSE} 
Bex<-Boxex%>%
  select(Time,Date,Group, MaleID, FemaleID, MaleCorn,`Male placement corn`, FemaleCorn, DyadDistance, DyadResponse, OtherResponse, Audience, IDIndividual1, IntruderID, Remarks )
glimpse(Bex)

View(Bex)
```

### 2.1.1 Merging Male placement corn and MaleCorn
* I want to process all the missing data in Bex. But before, I will merge the column **MaleCorn** and **Male placement corn** as the data of both columns is supposed to be together under "MaleCorn"
* Looking manually in the Bex table it seems that very few data is in **MaleCorn** while most of it seems to be in **Male placement corn**
* Every time there is a missing value in Male placement corn we can see a value in Male Corn, I will then create a new variable MaleCorn where every time that there is NA in male placement corn the value will be taken in MaleCornOld (previous malecorn). If there is no NA it will take the value of ´Male placement corn´
* I will first **rename MaleCorn to MaleCornOld**, then **check the amount of NA's** and then **merge "MaleCornOld" and "male placement corn"** into the **new variable "MaleCorn"**

```{r handling MaleCorn to MaleCornOld, echo=FALSE}

# Check if the dataset has the necessary columns before proceeding 
if ("MaleCorn" %in% colnames(Bex) && "Male placement corn" %in% colnames(Bex)) {
  
  # Rename MaleCorn to MaleCornOld
  names(Bex)[names(Bex) == "MaleCorn"] <- "MaleCornOld"

  # Calculate and print the number of common NAs before any operations
  common_na_count <- sum(is.na(Bex$MaleCornOld) & is.na(Bex$`Male placement corn`))
  cat("Number of rows with common NAs in MaleCornOld and 'Male placement corn':", common_na_count, "\n")

  # Create a new variable MaleCorn with no NAs, replacing NA with the first available value or 0
  Bex$MaleCorn <- ifelse(is.na(Bex$`Male placement corn`), Bex$MaleCornOld, Bex$`Male placement corn`)
  Bex$MaleCorn[is.na(Bex$MaleCorn)] <- 0

  # Count occurrences of 0 in MaleCorn and print the result
  zero_count <- sum(Bex$MaleCorn == 0)
  cat("Number of occurrences of 0 in MaleCorn:", zero_count, "\n")

  # Remove the original MaleCornOld and Male placement corn columns
  Bex$MaleCornOld <- NULL
  Bex$`Male placement corn` <- NULL

  # Check for remaining missing values in the new MaleCorn and print if any
  remaining_na <- sum(is.na(Bex$MaleCorn))
  cat("Number of remaining NA values in MaleCorn:", remaining_na, "\n")

} else {
  # Display a message or take alternative actions if columns are missing
  cat("Error: Required columns not found in the dataset.\n")
}

```

* I have found **1499 NA in common** between MaleCornOld and 'male placement corn', **1609 NA in Male placement corn** and **2685 in MaleCorn old**


* For the **merge of MaleCornOld and Male placement corn**, I used different conditions:
1.In this code, a new variable MaleCorn is created. If there is a missing value in Male placement corn, it takes the corresponding value from MaleCornOld; otherwise, it takes the value from Male placementcorn.
2.If there are no value in both MaleCornOld and Male placement corn (NA,NA) for a given row, I would like the code to display 0 as it means that no placement was given
* In this way, I should not loose any data, minimize the mistakes and already transform the NA's of this variable into a number which will remove the remaining NA's which are meant to be 0
* After the merge I found that there were **no NA's remaining** in the **"New" Male Corn** and that **1499 0's** where found in the column which **corresponds to the amount of common NA's found previously** between the **"Old" Male Corn** and **male placement corn**


### 2.1.2 Cleaning FemaleCorn

```{r FemaleCorn, echo=FALSE}
# Replace NA values in "FemaleCorn" with 0
Bex$FemaleCorn <- ifelse(is.na(Bex$FemaleCorn), 0, Bex$FemaleCorn)

# Check how many NA values are left in "FemaleCorn"
remaining_na <- sum(is.na(Bex$FemaleCorn))
cat("Number of remaining NA values in FemaleCorn:", remaining_na, "\n")
```

### 2.2 Cleaning variables with missing data

* Now in order to see where are located the missing points in the data, I'm going to **print** the variables **with and without NA's**

* The function **sapply** is used to apply the function **sum** for NA's to each column of the data frame, so each variable

```{r Find Missing data, echo=FALSE}
# Check for missing data
missingdata <- sapply(Bex, function(x) sum(is.na(x)))

# Print missing data
cat("Variables with Missing Data:\n")
kable(missingdata[missingdata > 0])

cat("Variables with No Missing Data:\n")
kable(missingdata[missingdata == 0])
  
```

* We can see that out of the 14 variables we have in **Bex** we have **9 variables with missing data** which are **Male ID, Female ID, DyadDistance, DyadResponse, OtherResponse, Audience, IDIndividual1, IntruderID, Remarks**:  I will proceed to clean these variables one by one 

* MaleID	19
* FemaleID	60
* DyadDistance	33
* DyadResponse	47
* OtherResponse	2758
* Audience	924
* ID Individual1 2143
* IntruderID 2737
* Remarks 2181

* Before making treating the NA's in the dataset I will make a backup of the data at this point: 
```{r backup berfore NA cleaning, echo=FALSE}
# Create a backup of the Bex dataset
Bex_beforeNA <- Bex
```   

### 2.3 Treating variables with missing data

#### 2.3.1 Cleaning "Remarks" - (2181 NA's)
* Since most of the time we did not have any remarks it is understandable that this variable contains 2181 NA's out of 2795 rows
* I will first transform every missing data in the column Remark into **No Remarks** and then check that the amount of "No remarks" found 

* After the changes we can effectively see that we have **2181 "No Remarks"** and we have no missing data left in that column, I will treat this column by hand once all the NA's have been removed from the dataset

```{r Remarks NA, echo=FALSE}

if (!"NoRemarks" %in% names(Bex)) {
  # Replace NA's with "No Remarks" in the "Remarks" column
  Bex$Remarks[is.na(Bex$Remarks)] <- "No Remarks"

 # Check how many times "No Remarks" appears in the "Remarks" column
  no_remarks_count <- sum(Bex$Remarks == "No Remarks")
  cat("Number of 'No Remarks' in the 'Remarks' column:", no_remarks_count, "\n")

  # Check if changes had been made for Remarks
  head(Bex$Remarks)

  # Count "No Remarks" and "Remarks"
  table_remarks <- table(ifelse(Bex$Remarks == "No Remarks", "No Remarks", "Remarks"))
  table_remarks
} else {
  cat("The 'NoRemarks' column already exists. No changes made.\n")
}


```


### 2.3.2 Cleaning "Intruder ID" - (2737 NA's)
* **Intruder ID** is a variable that contains the **name of the individuals that made and intrusion during a trial**.
* If more than one individual intruded, his name may be in the comments, which I will check when treating the data from this column
* Because nothing was entered when there was no intrusion, I will replace every NA's by **No Intrusion**
* Also, I will use a function to create a new dichotomic variable called **Intrusion**. Every time there is a value in IntruderID, it should display 1 (Yes), if not a 0 (No intrusion)


```{r IntruderID NA, echo=FALSE}

# Check if the 'Intrusion' column already exists
if (!"Intrusion" %in% names(Bex)) {
  # Replace NA's with "No Intrusion" in the "Intruder ID" column
  Bex$IntruderID[is.na(Bex$IntruderID)] <- "No Intrusion"

# Create a new dichotomic variable called "Intrusion"
Bex$Intrusion <- ifelse(Bex$IntruderID == "No Intrusion", 0, 1)

 # Check how many times "No Intrusion" appears in the "Intruder ID" column after replacement
  no_intrusion_count <- sum(Bex$IntruderID == "No Intrusion")
  cat("Number of 'No Intrusion' in the 'Intruder ID' column after replacement:", no_intrusion_count, "\n")
} else {
  cat("The 'Intrusion' column already exists. No changes made.\n")
}
```
* We previously had 2737 NA's in IntruderID while now we have the same amount of occurrences of IntruderID which shis that the transformation went as intended

#### 2.3.3 Cleaning "IDIndividual1" - (2143 NA's)

* IDIndividual1 is meant to report the name of the individual that did a behavior such as not approach, show aggression or loose interest during a trial
* I will now replace every NA in this column by **No individual** and print the amount of NA's left and the amount of changes made

  
  
```{r IDIndividual1 NA, echo=FALSE}
# Check if the "IDIndividual1" column exists in the dataset
if ("IDIndividual1" %in% names(Bex)) {
  # Count initial NA's for reference
  initial_na_count <- sum(is.na(Bex$IDIndividual1))

  # Replace NA in IDIndividual1 with "No individual"
  Bex$IDIndividual1[is.na(Bex$IDIndividual1)] <- "No individual"

  # Calculate the number of changes made (should be equal to initial_na_count if no other changes occurred)
  changes_made <- initial_na_count

  # Check for remaining NAs (there should be none left)
  remaining_na <- sum(is.na(Bex$IDIndividual1))

  # Print the results
  cat("Number of NAs replaced in IDIndividual1:", changes_made, "\n")
  cat("Number of remaining NA values in IDIndividual1:", remaining_na, "\n")
} else {
  # If the column does not exist, print a message
  cat("Error: 'IDIndividual1' column not found in the dataset.\n")
}


```



### 2.6 Cleaning "Audience" - (924 NA'S)
* Audience is made to report every name of individuals around our dyad during a given trial
* I will replace every NA by **No audience** as no entry means the absence of other individuals around
* I will also create a new variable called "Amount audience" that will have to tell me how many individuals are found in the column Audience 

```{r Audience NA, echo=FALSE}
# Initial count of NA in Audience
initial_na_audience <- sum(is.na(Bex$Audience))

# Creating amount of audience
Bex$AmountAudience <- ifelse(is.na(Bex$Audience), 0, lengths(strsplit(Bex$Audience, "; ")))

# Changing NA's in Audience to "No audience"
Bex$Audience[is.na(Bex$Audience)] <- "No audience"

# Calculate and print the number of changes made
changes_made_audience <- initial_na_audience - sum(is.na(Bex$Audience))
cat("Number of changes made in 'Audience':", changes_made_audience, "\n")

# Remaining NA's in Audience
remaining_na_audience <- sum(is.na(Bex$Audience))
cat("Remaining NA values in 'Audience':", remaining_na_audience, "\n")
```


### 2.7 Cleaning "OtherResponse" - (2758 NA'S)
```{r OtherResposne NA, echo=FALSE}
# Initial count of NA in OtherResponse
initial_na_other_response <- sum(is.na(Bex$OtherResponse))

# Replace NA in OtherResponse by "No Response"
Bex$OtherResponse[is.na(Bex$OtherResponse)] <- "No Response"

# Calculate and print the number of changes made
changes_made_other_response <- initial_na_other_response - sum(is.na(Bex$OtherResponse))
cat("Number of changes made in 'OtherResponse':", changes_made_other_response, "\n")

# Remaining NA's in OtherResponse
remaining_na_other_response <- sum(is.na(Bex$OtherResponse))
cat("Remaining NA values in 'OtherResponse':", remaining_na_other_response, "\n")
```


### 2.8 Cleaning of "Time"
* Since the reading of the data is more complicated without the time, which was usefull to know which trial was before or after, I changed the code made for Bex and added **Time** in the dataframe. Since I will need it for the cleaning of Dyaddistance, I will now extract the time from the date. Even if the date is wrong as seen in the first output, the time is correct. As in the second output, only the time has been kept

```{r Time, echo=FALSE}

head(Bex$Time)

# Convert 'Time' to POSIXct format
Bex$Time <- as.POSIXct(Bex$Time, format = "%Y-%m-%d %H:%M:%S")

# Extract only the time from 'Time' and assign it update Time'
Bex$Time <- format(Bex$Time, "%H:%M:%S")

head(Bex$Time)

```


### 2.9 Cleaning DyadDistance
* Before looking at the NA's of Dyaddistance I will remove the "m" that is in front of every number to      have a numerical variable
* Then I will look at the location of the NA's in the data to treat them case by case.


```{r DyadDistance NA, echo=FALSE}

# Check if the dataset has the necessary columns before proceeding 
if ("DyadDistance" %in% names(Bex)) {

  # Check if modifications are needed (avoiding unnecessary changes on multiple runs)
  if (!is.numeric(Bex$DyadDistance)) {
    
    # Remove "m" from DyadDistance and convert to numeric
    Bex$DyadDistance <- as.numeric(gsub("m", "", Bex$DyadDistance), errors = "coerce")
    
    # Identify NA values in DyadDistance
    NA_DyadDistance <- Bex[is.na(Bex$DyadDistance), ]
    
    # View the locations of NA values
    print(NA_DyadDistance)
    
    # Count the number of missing values in the DyadDistance column
    dyad_distance_missing_data <- Bex[is.na(Bex$DyadDistance), ]
    
    # Print the result
    cat("Number of NA values in DyadDistance column (using second approach):", nrow(dyad_distance_missing_data), "\n")
    
    # Find row indices with NA values in DyadDistance
    dyad_distance_na_row <- which(is.na(Bex$DyadDistance))
    
    # Print the row indices
    cat("Rows with NA values in DyadDistance column:", paste(dyad_distance_na_row, collapse = ", "), "\n")

  } else {
    cat("No modifications needed for DyadDistance. It already appears to be in the desired format.\n")
  }

} else {
  # Display a message or take alternative actions if columns are missing
  cat("Error: Required columns not found in the dataset.\n")
}

```



* We have 69 missing values in  DyadDistance. I will look at each row in it's context as the actual distance of the box was always dependent of the previous trials. I will start with the bigger number as for now the oldest trial is at the last row while the closest one is in row 1.



  - If **tolerance** was achieved **twice in a row**     =   <1m
  - If **aggression** (male agress female or female agress male), not approaching,or **loosing     interest** occured                                   =   >1m
  - If **distracted** or **intrusion** occured           =    same distance
  
  1. **24** - In trial23 (0m) there was aggression then at trial24 (1m) there was tolerance. The 24th trial is supposed to be at **1m**
  2. **27** - In trial25 (1m) there was not approaching then at trial26 (2m) there was tolerance.The 25th trial is supposed to be at **2m**
  3. **95** - In trial93 (2m ) there was male agress female then at trial 94 (3m) there was not approaching. The 95th trial is supposed to be at **4m**
  4. **492** - In trial490 (0m) there was tolerance then at trial491 (0m) there was tolerance. The 492nd trial is supposed to be at **0m**
  5. **744** - In trial742 (3m) there was aggression then at trial743 (4m) there was tolerance. The 744th trial is supposed to be at **4m**    
  6. **971** - In trial969 (0m) there was tolerance then at trial970 (0m) there was tolerance. The 971st trial is supposed to be at **0m**
  7. **1113** - In trial1111 (2m) there was tolerance then at trial1112 (0m) there was tolerance. The 1113th trial is supposed to be at **0m**
  8. **1130** - In trial1128 there was another dyad so we can not use this cell. Then at trial1129 (3m) there was not approaching. Nevertheless, we don't have any DyadResponse, i will thus **delete this row** 
  9. **1164** - In trial1162 (3m) there was not approaching then at trial1163 (3m) there was not approaching. The 1164th trial is supposed to be at **4m**
  10. **1261** - The two
  preivous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  11. **1341** - In trial1339 (0m) there was tolerance then at trial1340 (0m) there was tolerance. The 1341st trial is supposed to be at **0m**
  12. **1396** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  13. **1491** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  14. **1583** - In trial1581 (2m) there was not approaching and intrusion then at trial1582 (2m) there was not approaching. The 1583rd trial is supposed to be at **3m**
  15. **1683** - One trial only was made with tolerance (2m) but since there are no DyadResponse I will **delete this row**
  16. **1693** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  17. **1717** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  18. **1718** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  19. **1719** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  20. **1724** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  21. **1725** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  22. **1739** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  23. **1755** - since there are no DyadResponse I will **delete this row**
  24. **1756** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  25. **1757** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  26. **1764** - Since there are no DyadResponse I will **delete this row**
  27. **1779** - It seems like it was the first trial of the Dyad Pom Xian, if so, the distance has to be **5m**
  28. **1782** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  29. **1792** - Trial1791 was intrusion (4m) so this trial should be at **4m**
  30. **1799** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  31. **1800** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  32. **1840** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  33. **1841** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  34. **1868** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  35. **1869** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  36. **1888** - he two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  37. **1891** - Since there are no DyadResponse I will **delete this row**
  38. **1892** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  39. **1896** - Since there are no DyadResponse I will **delete this row**
  40. **1911** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  41. **1912** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  42. **1915** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  43. **1918** - In trial1916 (4m) there was tolerance then at trial1917 (4m) there was not loosing interest The 1918th trial is supposed to be at **4m**
  44. **1919** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  45. **1952** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  46. **1953** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  47. **1958** - In trial1956 (2m) there was tolerance then at trial1957 (2m) there was distracted. The 1958th trial is supposed to be at **2m**
  48. **1980** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  49. **1981** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  50. **1984** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  51. **1986** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  52. **1996** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  53. **2000** - In trial1997 and 1999 (5m) there was tolerance then at trial1999 (5m) there was intrusion. The 2000th trial is supposed to be at **4m**
  54. **2009** - Since there are no DyadResponse I will **delete this row**
  55. **2054** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  56. **2104** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  57. **2105** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  58. **2191** - In trial2189 (1m) there was not approaching then at trial2190 (2m) there was not approaching. The 2191st trial is supposed to be at **3m**
  59. **2233** - In trial2231 (3m) there was not approaching then at trial2232 (4m) there was not approaching. The 2233rd trial is supposed to be at **5m**
  60. **2234** - The trial did not happen because they where not at the right distance. I will thus **delete this row**
  61. **2287** - Since there are no DyadResponse I will **delete this row**
  62. **2437** - Since there are no DyadResponse I will **delete this row**
  63. **2569** - In trial2567 (1m) there was tolerance then at trial2568 (1m) there was tolerance. The 2569th trial is supposed to be at (0m)
  64. **2579** - In trial2577 (1m) there was tolerance then at trial2578 (0m) there was not approaching. The 2579th trial is supposed to be at **1m**
  65. **2580** - The two previous trials were made with another Dyad. Also DyadResponse is not available. I will thus **delete this row**
  66. **2643** - Since there are no DyadResponse I will **delete this row**
  67. **2676** - In trial2674 (1m) there was tolerance then at trial2675 (0m) there was tolerance. The 2676th trial is supposed to be at **0m**
  68. **2709** - In trial2707 (2m) there was tolerance then at trial2708 (2m) there was tolerance. The 2709th trial is supposed to be at **1m**
  69. **2729** - In trial2727 (3m) there wastolerance then at trial2728 (2m) there was tolerance. The 2729th trial is supposed to be at **2m**


* Now that I have looked at each missing line and saw which ones to keep, I decided to create a new variable called **Distance**. I will also to create a new variable called **No trial**.
* For the variable **Distance** I will replace each row where there was missing data with a value and I will delete the ones where no values could be assigned. This will allow me to have no missing data and find a number to each trial that has been done

* Before making the changes i'm gonna make a backup called **BackupbeforeDistanceNA**

```{r BackupdistanceNA, echo=FALSE}
# Create a backup of the dataset before making changes
BackupbeforeDistanceNA <- Bex

```

 
```{r Distance2, echo=FALSE}

# Ensure the DyadDistance column exists
if ("DyadDistance" %in% names(Bex)) {

  # Convert DyadDistance by removing 'm' and converting to numeric if necessary
  if (!is.numeric(Bex$DyadDistance)) {
    Bex$DyadDistance <- as.numeric(gsub("m", "", Bex$DyadDistance))
  }

  # Define the replacement values with correct indexing
  replacement_values <- c(
    `24` = 1, `27` = 2, `95` = 4, `492` = 0, `744` = 4, `971` = 0, `1113` = 0, `1164` = 4,
    `1341` = 0, `1583` = 3, `1779` = 5, `1792` = 4, `1840` = 0, `1868` = 0, `1918` = 4,
    `2000` = 4, `2191` = 3, `2233` = 5, `2569` = 0, `2579` = 1, `2676` = 0, `2709` = 1, `2729` = 2
  )

  # Check and apply replacements
  for (row_num in names(replacement_values)) {
    if (as.numeric(row_num) <= nrow(Bex)) {
      Bex$DyadDistance[as.numeric(row_num)] <- replacement_values[[row_num]]
    }
  }

  # Rows to delete, verifying their existence
  rows_to_delete <- c(1130, 1261, 1396, 1491, 1683, 1693, 1717, 1718, 1719, 1724, 1725, 1739, 1755, 1756, 1757, 1764, 1782, 1799, 1800, 1840, 1841, 1868, 1869, 1888, 1891, 1892, 1896, 1911, 1912, 1915, 1919, 1952, 1953, 1980, 1981, 1984, 1986, 1996, 2009, 2054, 2104, 2105, 2234, 2287, 2437, 2580, 2643)
  rows_to_delete <- rows_to_delete[rows_to_delete <= nrow(Bex)]

  # Deleting rows
  Bex <- Bex[-rows_to_delete, ]

  # Print the current status of NA's in DyadDistance
  cat("Number of NA's in DyadDistance after replacements and deletions:", sum(is.na(Bex$DyadDistance)), "\n")
  cat("Data size after deletions:", nrow(Bex), "\n")

} else {
  cat("Error: DyadDistance column not found in the dataset.\n")
}



# Find the row index where DyadDistance is NA
na_row_index <- which(is.na(Bex$DyadDistance))

# Print the row index
cat("Row index with NA in DyadDistance:", na_row_index, "\n")

``` 
*It seems that there is still the row 1925 with an NA in DyadDistance

70. **1925** - In trial1923 (2m) there was distracted then at trial1924 (2m) there was tolerance. The 2725th trial is supposed to be at **2m**

```{r LastNADyadDistance, echo = FALSE}
# Adding the 1925th trial with the distance set to 2m
Bex$DyadDistance[1925] <- 2

# Find the row index where DyadDistance is NA
na_row_index <- which(is.na(Bex$DyadDistance))

# Print the row index
cat("Row index with NA in DyadDistance:", na_row_index, "\n")


```



*In this modification, I added a check to see if the columns Dyadistance and Distance already exist in your dataframe (Bex). If they do, it prints a message saying that the modification has already been applied, and no changes are made. If they don't exist, it proceeds with the modifications. This way, running the code multiple times won't cause redundant changes.
  
* **24 values** were inserted in **Distance** to replace the NA's where the distance could be found by looking at the previous rows. The **46 remaining NA's** were then **removed** from Distance **leaving 0 remaining NA in  the variable "Distance"**


### 2.10 Cleaning Female and Male ID

* Before cleaning Female and Male ID, here is a list of every dyad of the box experiment and their respective groups. This will help us find the missing names when only one individual is missing out of the duo (either male or female):
  a. Sirk & Sey - BD
  b. Ouli & Xin - BD
  c. Piep & Xia - BD
  d. Oerw & Nge - BD
  e. Oort & Kom - BD
  
  f. Ginq & Sho - AK
  g. Ndaw & Buk - Ak
  
  h. Xian & Pom - AK
  i. Guat & Pom - Ak
  
* Note that the 4 letter codes correspond to the femaleID, the 3 letter codes to the males ID and the 2 letter codes to the group name of the monkeys



* I need to check where are the NA's in both FemaleID and Male ID by looking at the rows where data is missing. Since every trial was made with a Dyad and never with an single individual, treating these two columns together makes more sense. If both individuals are missing I may have to delete the row.


```{r FemaleMaleID NA, echo=FALSE}
   
# Checking for location of missing values in FemaleID and MaleID

# Missing values in FemaleID
female_missing_rows <- which(is.na(Bex$FemaleID))
cat("Row numbers with missing values in FemaleID: ", female_missing_rows, "\n")
cat("Number of missing values in FemaleID: ", length(female_missing_rows), "\n")

# Missing values in MaleID
male_missing_rows <- which(is.na(Bex$MaleID))
cat("Row numbers with missing values in MaleID: ", male_missing_rows, "\n")
cat("Number of missing values in MaleID: ", length(male_missing_rows), "\n")



# Check where we have Na in both Female and Male ID  and in whcih rows
# Row numbers with missing values in both FemaleID and MaleID
both_missing_rows <- which(is.na(Bex$FemaleID) & is.na(Bex$MaleID))

# Count of rows with missing values in both FemaleID and MaleID
both_missing_count <- length(both_missing_rows)

cat("Number of rows with missing values in both FemaleID and MaleID: ", both_missing_count, "\n")
cat("Row numbers with missing values in both FemaleID and MaleID: ", toString(both_missing_rows), "\n")


# Rows with missing values in FemaleID but not in MaleID
only_female_missing_rows <- setdiff(female_missing_rows, both_missing_rows)

# Count of rows with missing values only in FemaleID
only_female_missing_count <- length(only_female_missing_rows)

cat("Number of missing values in FemaleID not in MaleID: ", only_female_missing_count, "\n")
cat("Row numbers with missing values in FemaleID not in MaleID: ", toString(only_female_missing_rows), "\n")


```
    
    
* **FemaleID** has **41 NA's** while they are **18 NA's** in **Male ID**
* In these missing data, we have **18 NA's** that are in common between FemaleID and MaleID which represents the totality of the missing values in MaleID

* All the missing data in MaleID are found in consecutive rows, from row **1693** to row **1710** and are from the group Noha (NH) on the 19th of april 2023. We can also see that trials had bee made in the same day, and looking at the time of the experiment, the previous trials made and the audience we can see that these NA's in female and male ID we can asses that the individuals involved were **Xian** for the female ID and **Pom** for the **MaleID**. I will thus replace these values using a condtion. These NA's in Noha (Trial 1693 to 1710) are the only NA's that MaleID has and are the only NA's of female ID in Noha. I will thus replace every NA of **MaleID NA in Noha** with **Pom** and every **Female ID NA in Noha** with **Xian**



```{r RemoveMaleIDNA, echo=FALSE}

# Assuming Bex is your dataframe and you want to update it directly
Bex <- Bex %>%
  mutate(
    MaleID = ifelse(is.na(MaleID) & Group == "Noha", "Pom", MaleID),
    FemaleID = ifelse(is.na(FemaleID) & Group == "Noha", "Xian", FemaleID)
  )

# Checking and reporting the updated status of missing values
# For MaleID
male_missing_after <- sum(is.na(Bex$MaleID))
cat("Number of remaining NA values in MaleID after replacement: ", male_missing_after, "\n")

# For FemaleID
female_missing_after <- sum(is.na(Bex$FemaleID))
cat("Number of remaining NA values in FemaleID after replacement: ", female_missing_after, "\n")

# For both MaleID and FemaleID
both_missing_after <- sum(is.na(Bex$MaleID) & is.na(Bex$FemaleID))
cat("Number of rows with missing values in both MaleID and FemaleID after replacement: ", both_missing_after, "\n")


```





* In order to clean FemaleID, I will use the data from the now complete MaleID. I will use conditions stating that depending which name is found in MaleID when there is an NA in FemaleID, a certain name will have to replace the NA in female ID


* Before automating the process I will check manually the data to see if they are any exceptions or mistakes

```{r CheckFemaleIDNA, echo=FALSE}


# Print rows with missing values in FemaleID
cat("Rows with missing values in FemaleID:\n")
print(Bex[is.na(Bex$FemaleID), ])


```

  If there is NA in femaleID, we will replace the value with 
    - Sirk if MaleID is Sey
    - Ouli if MaleID  is Xin
    - Piep if MaleID  is  Xia 
    - Oerw if MaleID  is  Nge 
    - Oort if MaleID  is  Kom 
    - Ginq if MaleID  is  Sho 
    - Ndaw if MaleID  is  Buk 
    
    
```{r FemaleMaleID Check}

library(dplyr)

# Using dplyr to summarize combinations of MaleID and FemaleID
combinations_summary <- Bex %>%
  group_by(MaleID, FemaleID) %>%
  summarise(Count = n(), .groups = 'drop') %>%
  arrange(desc(Count))

# View the results
print(combinations_summary)

```

```{r FemaleID, echo=FALSE}

library(dplyr)

# Assuming Bex is your data frame
Bex <- Bex %>%
  mutate(
    FemaleID = case_when(
      is.na(FemaleID) & MaleID == "Sey" ~ "Sirk",
      is.na(FemaleID) & MaleID == "Xin" ~ "Ouli",
      is.na(FemaleID) & MaleID == "Xia" ~ "Piep",
      is.na(FemaleID) & MaleID == "Nge" ~ "Oerw",
      is.na(FemaleID) & MaleID == "Kom" ~ "Oort",
      is.na(FemaleID) & MaleID == "Sho" ~ "Ginq",
      is.na(FemaleID) & MaleID == "Buk" ~ "Ndaw",
      TRUE ~ FemaleID  # Keep the existing value if none of the conditions are met
    )
  )


# Count NA values in MaleID
na_count_male <- sum(is.na(Bex$MaleID))
cat("Number of NA values in MaleID: ", na_count_male, "\n")

# Count NA values in FemaleID
na_count_female <- sum(is.na(Bex$FemaleID))
cat("Number of NA values in FemaleID: ", na_count_female, "\n")


```


* After the use of the conditions in FemaleID I could see the changes where successfully done and that 0 NA's are remaining in both FemaleID and MaleID


### 2.12 Dyad Response (7)

* The last variable I still have to treat for NA's is DyadResponse. Before treating the NA's we had 47 NA's we know that we treated most of them we have only 7 remaining. These NA's can be found at the rows **871, 1163, 1219, 1339, 1579,1888 and 1962** 


```{r DyadResposneNA, echo=FALSE}

# Find rows with NA values in DyadResponse
na_dyadresponse_rows <- which(is.na(Bex$DyadResponse))
cat("Rows with missing values in DyadResponse: ", toString(na_dyadresponse_rows), "\n")


# Display the lines with NA values in DyadResponse along with their row numbers
cat("Lines with missing values in DyadResponse:\n")
print(Bex[na_dyadresponse_rows, ])

View(Bex) 
```


* Row 871: The previous row was tolerance at 1m and the next tolerance at 0 which means that the row 871 should be **Tolerance** for DyadResponse

* Row 1163: The value can not be found from the other rows so I will **delete** row 1163

* Row 1219: The previous row was not approaching at 2m and the next is tolerance at 2m and tolerance at 1m, which means that the row 1219 should be **Tolerance** for DyadResponse

* Row 1339: The previous row was tolerance at 0m while the next one was tolerance at 0m, which means that the tow 1339 should be **Tolerance** for DyadResponse

* Row 1579: The value can not be found from the other rows so I will **delete** row 1579

* Row 1888: The value can not be found from the other rows so I will **delete** row 1888

* Row 1962: The value can not be found from the other rows so I will **delete** row 1962




```{r DyadResposneNATreatment, echo=FALSE}
# Load the data (assuming data is already loaded as Bex)

# Deleting specific rows with unresolvable NA values
Bex <- Bex[-c(1163, 1579, 1888, 1962), ]

# Updating specific rows with resolved values
Bex$DyadResponse[c(871, 1219, 1339)] <- "Tolerance"

# Removing remaining NA values from the dataset
Bex <- Bex[!is.na(Bex$DyadResponse), ]

# Count the remaining NA values in DyadResponse
remaining_na_count <- sum(is.na(Bex$DyadResponse))

# Display the results
cat("Number of remaining NA values in DyadResponse: ", remaining_na_count, "\n")

```


### 2.13 Final check: remaing NA's in Bex?

```{r Check if Remaing NA in Bex, echo=FALSE}
# Calculate the number of NA values in each column
na_counts <- sapply(Bex, function(x) sum(is.na(x)))

# Print the number of NA values for each column
cat("Final check of NA values in Bex:\n")
print(na_counts)

```

# 3. Correction and creation of New Variables 

### 3.1 Making a backup of Bex
* Before making new changes I will make a backup of my dataset at this point

```{r Backup Bex 1, include=FALSE}
# Create a backup
backup_Bex <- Bex
```


### 3.2 Treating Remarks before processing with new modifications
* Since I have removed all the missing data from the different columns, I now have to correct potential mistakes that can be found and create new variables to be able to manipulate better my data.
* Since the column remarks contains corrections and additional information, I will treat it now


* Before that lets check how many remarks we have in our dataset, how many of the main keywords we can find and make a visual representation of it

#### 3.2.2 Vizualization of the Remarks Keywords


* Before making any changes I will make a count of the total amount of remarks and a count and barplot of the main keywords in the column to see in which proportion they are found. It has to be noted that some of the words are used in different contexts and have different meaning. This is why I will clean them manually

```{r Remars Counts, echo=FALSE}
# Calculate the count of "No Remarks"
count_no_remarks <- sum(Bex$Remarks == "No Remarks")

# Calculate the count of actual remarks (different than "No Remarks")
count_actual_remarks <- sum(Bex$Remarks != "No Remarks")

# Print the results
cat("Number of 'No Remarks' entries: ", count_no_remarks, "\n")
cat("Number of actual remarks entries: ", count_actual_remarks, "\n")

```

* There will be 599 entries I will have to treat manually in the Excel Spreadsheet for the Remarks

```{r Remarks Exploration, echo=FALSE}



# Define the keywords list properly before the loop
keywords <- c("open", "work", "trial", "approach", "scare", "intrude", "stole", "steal", "corn", "ate", "audience", "sec", "before", "after", "left", "na", "alarm","box", "bge","alarm", "distracted")

# Reinitialize to store updated counts
keyword_counts <- data.frame(Keyword = character(), Counts = integer(), stringsAsFactors = FALSE)

# Recalculate counts
for (kw in keywords) {
  count <- sum(str_detect(tolower(Bex$Remarks), kw))
  keyword_counts <- rbind(keyword_counts, data.frame(Keyword = kw, Counts = count))
}

# Plot with counts on bars
ggplot(keyword_counts, aes(x = reorder(Keyword, -Counts), y = Counts)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  geom_text(aes(label = Counts), hjust = -0.1, size = 3) +
  coord_flip() +
  labs(title = "Frequency of Main Keywords in Remarks", x = "Keyword", y = "Frequency") +theme_minimal()

# Calculate and print the total number of keyword occurrences
total_keyword_occurrences <- sum(keyword_counts$Counts)
cat("Total number of keyword occurrences in the Barplot: ", total_keyword_occurrences, "\n")

```


#### 3.2.3 Exporting of Bex
* I will now export the dataset and treat manually treat the remarks in an Excel spreadsheet before uploading it again and creating a new dataframe. I will also print a Glimpse of Bex to have information before the manual changes

```{r Exporting Bex For Remarks, echo=FALSE}
#GLimpse function to see the summary and  the structure

cat("Glimpse of the Bex Before treating Remarks:\n\n")
glimpse(Bex)

#Exporting Bex as speadsheet to clean manually the remarks
write.xlsx(Bex, "Bex_for_manual_cleaning.xlsx", rowNames = TRUE)

#Using Getwd to find path of the BEx Excel sheet
getwd()

```

#### 3.2.4 Journal of manual changes in Bex excel spreadsheet

* Before treating all the data in the Remarks I will create a few columns to redistribute information
  1. **Context**: To add contextual information 
  2. **SpecialBehaviour** : To report any particular behaviour an individual could have done during a trial
  3. **Got corn**, to see if the individual got the corn or not

* Also whenever i will have treated a remark, i will replace it with "Treated". And if I have to delete the row I'll write "Delete". After re importing the data I will make a count of these changes to see if I still have the correct amount of cells and changes that have been done


* 1. Creation of the columns **Context**, **SpecialBehaviour** and **GotCorn**
* 2. Default values for the new columns are
**NoContext**, **NoSpecialBehaviour** & **Yes**

  a.Context: **BoxMalfunction**, **BoxOpenedBefore**, **NoExperiment**, **Agonistic**, **Guat;Ap;Xian**, **CornLeak**, **BetweenGroupEncounter**, **ContactCalling**, 
  
  b.SpecialBehaviour **Oerw;Vo;Exp**, **Sey;Ap;AfterOpen**, **Oerw;Vo;Exp,Nge;Vo;Exp**, **Sirk;ApAfter30**, **Sirk;Av;Oerw**, **Oerw;Lo**,**Sey;Sf;Oort,Oort;At;Kom**, **Kom;Ap;AfterOpen**, **Sey;Ch,Sirk**, **Xin;Hesitation**. **Xia;Sf;Piep**, **Pom;Sf;Xian**,**Kom;Sf;Oort**, **Sey;Sf;Sirk**, **Xia;Sf;Piep,Piep;Sf,XIa**, **Oort;At;Kom**, **Sey;Rt;Sho;Ap**, **Sho;Rt;Ginq;Ap**, **Buk;Sf;Ndaw**, **Sho;Rt;Ndaw;Ap**, **Oort;Sf;Kom**, **Ginq;Sho;Ap;After30**, **Ndaw;Sc,Buk;Sf**, **Ndaw;Ap;After30**, **Kom;Ap;After30**, **Xia;Piep;Ap;After30**, **Pom;Bi;Xian**, **Sho;Ndaw;Av;Buk**, **Kom;Sf;Oort**, **Kom;St;Oort,Oort;St;Kom**, **Sey;Hi;Sirk**, **Obse;Ap;Piep;Av**,**Piep;Sf;Xia**, **Sirk;ApWhenPartnerLeft**, **Sey;Hh;Sirk**, **Xia;Sf;Piep;Sc**, **Xia;Piep;ShareFood**, **Piep;Ap;After30,Xia;Mu;Piep**, **Oort;St;Sirk;Ja,Sey;Sf**, **Pom;Sf;Xian**, **Ndaw;ApWhenPartnerLeft**, **Xian;At;Pom,Gaya;Su**, **Xian;Sf;Pom**, **Xian;Hesitation**, **Xia;ApWhenPartnerLeft**,**Sirk;Hesitation**, **Ginq;Hesitation**, **Sey;Ap;Kom;Av**, **Oort;Sc;Kom**, **Xian; Pom**, **Pom;Ap;Xian**, **Pom;Ap;Xian,Xian;Rt**, **Sey;Ap;Sirk;Rt**, **Sey;St;Sirk;Ig**, **Xia;Asf;Piep**, **Piep;ApWhenPartnerLeft**, **Sho;Ap;After30**, **Ginq;ApWhenPartnerLeft**, **Pom;Sf;Xian;Sf;Pom**, **Xian;ApWhenPartnerLeft**, **Piep;Ch;Sirk**, **Sey;St;Sirk**, **Ndaw;Ap;After30**, **Xian;Ap;After30**, **Xian;St;Prai**, **Pom;Sf;Xian;Vc**, **Kom;Ap;After30**, **Kom;ApproachWithPartner**, **Oort;ApWhenPartnerLeft**, **Sho;Ap;After30**,**Ginq;Ap;After30**, **Ginq;ApproachWithPartner**, **Ndaw;Hesitation**, **Oerw;Hesitation**, **Oerw;ApWhenPartnerLeft**. **Piep;Ap;After30**, **Sirk;Ap;After30**, **Xia;Ap;After30**, **Ouli;Gr;BBOuli**, **Oerw;Ap;After30**, **Sirk;Hesitation**, **Sey;Ap;Sirk;Av**, **Ouli;Ap;Xia;Av**, **Xin;Ap;After30**, **Sho;Sf;Ginq;Sc**, **Xia;ApWhenPartnerLeft**, **Sey;Ap;Sirk;Ja**, **Nge;Oerw;ShareFood**, **Nge;Ap;Oerw;Oerw;At,Obse;At;Nge**,
  
  

  c.GotCorn: **No;Nge**, **No;Piep**, **No;Xian**, **No;Oort**, **No;Sirk**, **No;Kom**, **No;Ndaw**, **No;Kom**, **No;Oort**, **No;Xia**, **No;Buk**, **No;Sho**, **No;Sey,No;Piep**, **No;Ginq**
  
  d. Remarks: **Treated**, **TODelete**

* 4. Values set for exsting columns

  a. IntruderID: **Sey**, **Oerw**, **Guat**, **Kom**, **Gris**, **Sho**, **Oerw; Ouli**, **Guat; Gri**, **Xop**, **Obse**, **Oort**, **Obse; Sey**, **Ginq; Ghid**, **Xia**, **Grif**, **Sey**, **Gree; Gran**, **Godu; Gub**, **Gran**, **Oerw; Nak**, **Ghid**, **Buk**, **Oup**

  b. DyadDistance: **6**, **7**, **8**, **9** , **1**
  
  c. Audience: **UnidentifiedAudience**, **Ouli; Riss**, **Gris**, **Sey**, **Sey; Piep; Sirk, Oup Ome**
  
  d. IDIndividual1: **Piep**, **Oort; Kom**, **Ndaw; Buk**, **Sho; Ginq**, **Ndaw, Buk**, **Xian, Pom**, **Oort; Kom**, **Buk; Ndaw**, **Sirk; Sey**, **Xin; Ouli**, **Oerw; Nge**
  
  e. DyadResponse: **Tolerance**, **Not approaching; Losing interest**, **Losing interest; Intrusion**
  
  


  

  
### 3.3 Re Uploading the dataset after the treatment of the Remarks 

* Now that I have manually treated the remarks in a spreadsheet I will re import the dataset 
```{r BexImport After Manual Cleaning, echo=FALSE}
# Import the Excel file
BexClean <- read_excel("Bex_After_manual_cleaning.xlsx")

#GLimpse of Bex Clean
glimpse(BexClean)

#Head of Bex Clean
head(BexClean)
```


* And Check for any remaining NA's in BexClean

```{r NABexClean, echo=FALSE}
# Check for NA values in specific columns
context_na_count <- sum(is.na(BexClean$Context))
special_behaviour_na_count <- sum(is.na(BexClean$SpecialBehaviour))
got_corn_na_count <- sum(is.na(BexClean$GotCorn))

# Check for NA values in BexClean
bexclean_na_count <- sum(is.na(BexClean))

# Print the counts of NAs
cat("Number of NA entries in Context: ", context_na_count, "\n")
cat("Number of NA entries in SpecialBehaviour: ", special_behaviour_na_count, "\n")
cat("Number of NA entries in GotCorn: ", got_corn_na_count, "\n")
cat("Number of NA entries in BexClean: ", bexclean_na_count, "\n")

```



### 3.4 Time - Creation of Period and Hour
* Time : I considered looking at the time sections in which we did the expermiment. I will thus look at the time ranges (max and min in the day / latest and earliest time) before separating the day in different sections to have an idea in which part of the day most of the experiments occured. This will not be used in my analysis, but if I wanted to, I could interesting to compare the amount of experimentations made per day and have a line indicating the time of sunrise. 

```{r Time Periods, include=FALSE}
BexClean <- BexClean %>%
  mutate(Time = as.POSIXct(Time, format = "%H:%M:%S"),
         Period = case_when(
           between(hour(Time), 6, 8) ~ "6 to 8",
           between(hour(Time), 8, 10) ~ "8 to 10",
           between(hour(Time), 10, 12) ~ "10 to 12",
           between(hour(Time), 12, 14) ~ "12 to 14",
           between(hour(Time), 14, 17) ~ "14 to 17",
           TRUE ~ NA_character_
         )
  )

```
* The **Minimum Time** in the dataset is **06:03:26*** while the **Maximum Time** is at **16:36:59**
* In my box experiment I have this variable called time that tells me when the experiment was done. I don't think I need this information per se. I was wondering if it could be easy and interesting to see from when to when the time occurs and then separate this time in a few sections like early, monring, morning, miday, afternoon, end of the day
* a.6 to 8 : Early morning
  b.8 to 10: Morning
  c.10 to 12: Noon
  d.12 to 14: Afternoon
  e.14 to 17: End of the day
  
* Last, I want to create a variable called Hour that will take the value in Time and  round it to the hour in which it is ex: from 06:00 to 06:59 -> 6, from 07:00 to 07:59 -> 7 etc...
* This will allow me to see when most of the trials occured with more detail and I will be to see in which hour most of the trial happened. Nevertheless Period will be better for an improved readability
```{r Hour, include=FALSE}

BexClean <- BexClean %>%
  mutate(Time = as.POSIXct(Time, format = "%H:%M:%S"),  # Convert Time back to POSIXct
         Hour = floor_date(Time, "hour"),  # Create Hour variable
         Hour = format(Hour, "%H:%M:%S"),  # Format Hour for display
         Time = format(Time, "%H:%M:%S"))  # Format Time for display


```

### 3.5 Date - Creation of Month and Day
*  i want to Create a variable called month to see the month of the experiment and day so I know which day of the experiment it was (1st, 10th, 1000th..)
```{r Month and Day, include=FALSE}

# Assuming 'Date' is the name of your variable
BexClean <- BexClean %>%
  arrange(Date) %>%  # Arrange data in ascending order of Date
  mutate(
    Day = as.numeric(difftime(Date, min(Date), units = "days")) + 1,  # Assign a unique day number
    Month = format(Date, "%Y-%m")  # Include both year and month in Month variable
  )

```



### 3.6 Male and Female ID - Creation of Dyad, Trial and Session

* I will use Female and Male ID to create different variables
  1. While checking if there are still any mistakes  in **FemaleID and MaleID** using **unique**, I saw that some of the names are in the wrong rows. I want the **3 letter male codes** whether they are in the column FemaleID or MaleID to be in the **new column Male** while I want the **4 letter female codes** whether they are in FemaleID or MaleID to be in the **new column Female** before checking again with unique that the transformation worked. I will use mutate
```{r Female Male ID Check, echo=FALSE}
# Unique outputs for FemaleID
unique_female_ids <- unique(BexClean$FemaleID)
cat("Unique Female IDs:", unique_female_ids, "\n")

# Unique outputs for MaleID
unique_male_ids <- unique(BexClean$MaleID)
cat("Unique Male IDs:", unique_male_ids, "\n")

# Summary table
beforesummary <- table(BexClean$FemaleID, BexClean$MaleID)
kable(beforesummary)

```
1. Create a variable called Male that in each row will take the name of the **3 letter code** that is either in MaleID or Female ID and a variable called Female that in each row will take the name of the **4 letter code** that is either in MaleID or FemaleID

```{r Female Male ID correction, echo=FALSE}

BexClean <- BexClean %>%
  mutate(
    Male = ifelse(nchar(MaleID) == 3, MaleID, ifelse(nchar(FemaleID) == 3, FemaleID, NA)),
    Female = ifelse(nchar(FemaleID) == 4, FemaleID, ifelse(nchar(MaleID) == 4, MaleID, NA)),
    Dyad = paste(Male, Female, sep = " ")
  )

# Display and verify the changes
unique_dyads <- unique(BexClean$Dyad)
cat("Unique Dyads:", unique_dyads, "\n")
kable(table(BexClean$Dyad))


unique_combinations <- unique(BexClean[, c("Male", "Female")])
cat("Unique Male-Female Combinations:")
print(unique_combinations)


```
  

  2. Create the variable called **Dyad** created by combining the name of FemaleID and MaleID into one name with a space between the two codes. For information the 3 letter code is the name of the female while the 4 letter code is the name of the male like displayed here with the correct dyads;
  
  * The correct dyads are:
    - Buk Ndaw	
    - Kom Oort	
    - Nge Oerw	
    - Pom Guat	
    - Pom Xian	
    - Sey Sirk	
    - Sho Ginq	
    - Xia Piep	
    - Xin Ouli	


  * While the dyads we have now in the datset are;
    - Buk Ginq	6
    - Buk Ndaw	259
    - Kom Oort	366
    - Nge Oerw	183
    - Pom Guat	5
    - Pom Xian	259
    - Sey Sirk	587
    - Sho Ginq	277
    - Xia Piep	610
    - Xin Oort	4
    - Xin Ouli	186


 
```{r Identify Wrong Dyads, echo=FALSE}

# Define the correct dyads
correct_dyads <- c("Buk Ndaw", "Kom Oort", "Nge Oerw", "Pom Guat", "Pom Xian",
                   "Sey Sirk", "Sho Ginq", "Xia Piep", "Xin Ouli")

# Identify the rows with wrong dyads
wrong_rows <- which(!BexClean$Dyad %in% correct_dyads)

# Print the wrong rows and the dyads in those rows
print("Wrong Rows:")
print(wrong_rows)
print("Wrong Dyads:")
print(BexClean$Dyad[wrong_rows])

```

 * They are a 10  **wrong dyads** that I will have to identify in the dataset and manually correct, those wrong dyads to change and identify are:
    -Buk Ginq - 6 occurences
    -Xin Oort - 4 occurences

  * I will change the occurences of **Buk Ginq** to **Sho Ginq** for **row 613 to 617** and **row 931**. I know these trials are with Sho Ginq because the comments mentioned Sho in them while Male(ID) gave Buk which was a mistake
  * For the **rows from 2710 to 2713** since, Ouli is in the audience it is unlikely that we had trials with the dyad **Xin Ouli**. Also I think they are little chances that the names of both individuals were entered wrong. I will replace these occurences where we had **Xin Oort** by **Kom Oort**
  
  * I thus want **Buk** to be replaced in male ID in rows 613 to 617 and row 913 with **Sho** and, **Xin** to be replaced by **Kom** in rows 2710 to 2713 in Male ID before updating Dyad
  
  
* If Rows 613 to 617 and 931 are coded with Buk for MaleId and Ginq for FemaleId replace Male by Sho  


  
```{r Correct Wrong Dyads, echo=FALSE}

# Define the correct dyads
correct_dyads <- c("Buk Ndaw", "Kom Oort", "Nge Oerw", "Pom Guat", "Pom Xian",
                   "Sey Sirk", "Sho Ginq", "Xia Piep", "Xin Ouli")

# Identify rows to be corrected
rows_to_correct_sho <- which(BexClean$MaleID == "Buk" & BexClean$FemaleID == "Ginq")
rows_to_correct_kom <- which(BexClean$MaleID == "Xin" & BexClean$FemaleID == "Oort")

# Print rows to be corrected
cat("Rows to correct Sho Ginq:\n")
print(rows_to_correct_sho)
cat("Rows to correct Kom Oort:\n")
print(rows_to_correct_kom)

# Apply corrections
BexClean <- BexClean %>%
  mutate(
    MaleID = ifelse(row_number() %in% rows_to_correct_sho, "Sho", MaleID),
    MaleID = ifelse(row_number() %in% rows_to_correct_kom, "Kom", MaleID),
    Dyad = paste(MaleID, FemaleID, sep = " ")
  )

# Extract Male and Female after correction
BexClean <- BexClean %>%
  mutate(
    Male = ifelse(nchar(MaleID) == 3, MaleID, ifelse(nchar(FemaleID) == 3, FemaleID, NA)),
    Female = ifelse(nchar(FemaleID) == 4, FemaleID, ifelse(nchar(MaleID) == 4, MaleID, NA)),
    Dyad = paste(Male, Female, sep = " ")
  )

# Validate the corrections
wrong_rows_after_correction <- which(!BexClean$Dyad %in% correct_dyads)

# Print the wrong rows and the dyads in those rows after correction
cat("Wrong Rows After Correction:\n")
print(wrong_rows_after_correction)
cat("Wrong Dyads After Correction:\n")
print(BexClean$Dyad[wrong_rows_after_correction])

# Check if all dyads are now correct
all_correct <- all(BexClean$Dyad %in% correct_dyads)
if (all_correct) {
  cat("All dyads are now correct.\n")
} else {
  cat("There are still some incorrect dyads.\n")
}

# Display the final summary of dyads
unique_dyads <- unique(BexClean$Dyad)
cat("Unique Dyads after correction:", unique_dyads, "\n")
kable(table(BexClean$Dyad))

# Print how many rows have been changed
cat("Number of rows changed to Sho Ginq:", length(rows_to_correct_sho), "\n")
cat("Number of rows changed to Kom Oort:", length(rows_to_correct_kom), "\n")

```

  3. Create the variable called **Trial** where the data will be **sorted by date and dyad** in order to see how many trials have been done with each individual: **One row (per dyad) = one trial** and the    variable called **Day** where the data will be **sorted by date and dyad and day** in order to see how many sessions have been done with each individual: **One day (per dyad) = one session**
  Now, let's proceed with creating the Dyad variable, Trial, and Day:
  
  
```{r Dyad and Day, echo=FALSE}
# Create Trial variable
BexClean <- BexClean %>%
  arrange(Date, Dyad) %>%
  group_by(Dyad) %>%
  mutate(Trial = row_number())

# Create Day variable  # (Changed 'Session' to 'Day' for better clarity)
BexClean <- BexClean %>%
  arrange(Dyad, Date) %>%
  group_by(Dyad, Date) %>%
  mutate(Day = cur_group_id())

```
4. Make a summary of trial and session so I can see see how many trials and sessions have been done with the individuals
```{r Dyad and Day Summary, echo=FALSE}
# Step 1: Summarize the Trials and Days
summary_trial <- BexClean %>%
  group_by(Dyad) %>%
  summarise(Num_Trials = max(Trial)) %>%
  arrange(desc(Num_Trials))  # Sort by Num_Trials in descending order

summary_Day <- BexClean %>%
  group_by(Dyad) %>%
  summarise(Num_Days = max(Day)) %>%
  arrange(desc(Num_Days))  # Sort by Num_Days in descending order

# Step 2: Print the results with better presentation
cat("Trial Summary:\n")
kable(summary_trial, col.names = c("Dyad", "Amount of Trials"), caption = "Summary of Trials")

cat("\nDay Summary:\n")
kable(summary_Day, col.names = c("Dyad", "Number of Days"), caption = "Summary of Days")

# Calculate Mean for Trials and Days
mean_trials <- mean(summary_trial$Num_Trials)
mean_days <- mean(summary_Day$Num_Days)

# Step 3: Plot the summaries

# Plot for Trials
plot_trials <- ggplot(summary_trial, aes(x = reorder(Dyad, -Num_Trials), y = Num_Trials, fill = Dyad)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Num_Trials), vjust = -0.5, size = 4) +
  geom_hline(yintercept = mean_trials, linetype = "dashed", color = "red") +
  annotate("text", x = Inf, y = mean_trials, label = paste("Mean:", round(mean_trials, 2)), hjust = 1.1, vjust = -0.5, color = "red") +
  labs(title = "Amount of Trials per Dyad", x = "Dyad", y = "Amount of Trials") +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank(), text = element_text(size = 12), axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_brewer(palette = "Set1")

# Plot for Days
plot_days <- ggplot(summary_Day, aes(x = reorder(Dyad, -Num_Days), y = Num_Days, fill = Dyad)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Num_Days), vjust = -0.5, size = 4) +
  geom_hline(yintercept = mean_days, linetype = "dashed", color = "red") +
  annotate("text", x = Inf, y = mean_days, label = paste("Mean:", round(mean_days, 2)), hjust = 1.1, vjust = -0.5, color = "red") +
  labs(title = "Number of Days per Dyad", x = "Dyad", y = "Number of Days") +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank(), text = element_text(size = 12), axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_brewer(palette = "Set1")

# Display the plots
print(plot_trials)
print(plot_days)
```


5. After relfection I decided to **remove every column** that is with PomGuat since they are not enough trials for this Dyad and since we then changed PomGuat for PomXian. I have 5 occurnces to change. For easier manipulation I will remove every row where there is **Guat**

```{r Remove PomGuat, echo=FALSE}

# Count the rows before modifications
before_rows <- nrow(BexClean)

# Remove rows where "Guat" is present in FemaleID
BexClean <- BexClean %>% filter(!grepl("Guat", FemaleID, ignore.case = TRUE))

# Count the rows after modifications
after_rows <- nrow(BexClean)

# Display the change in rows
cat("Change in Rows: ", after_rows - before_rows, "\n")

```

  



### 3.7 Female and Male Placement Corn 

* The idea is that for each Dyad, we gave an amount of corn to attract the monkey of a dyad to the right distance of his partner for a trial by putting corn in experiment box that he could get by approaching. We repeated this step as much as needed to have our Dyad at the desired distance to continue the trials from the previous day of experimentation. This means I will only Keep the last number per dyad and day for each day. 
* I decided to create **two variables**, that are called **PlacementMale** and **PlacementFemale** that will only keep the final amount of corn given to each individual within a day of experiment

```{r FemaleMale Corn, echo=FALSE}

BexClean <- BexClean %>%
  arrange(Dyad, Date) %>%
  group_by(Dyad, Day) %>%
  mutate(
    PlacementMale = last(MaleCorn),
    PlacementFemale = last(FemaleCorn)
  )

# Check if columns are created successfully
if ("PlacementMale" %in% names(BexClean) && "PlacementFemale" %in% names(BexClean)) {
  cat("Placement columns were created successfully.\n")
} else {
  cat("Error: Placement columns were not created.\n")
}
```

```{r PlacementMaleFemale Plot, echo=FALSE}

# Summarize the total amount of placement corn given to each male
summary_male_corn <- BexClean %>%
  filter(!is.na(Male)) %>%
  group_by(Male) %>%
  summarise(Total_Corn = sum(PlacementMale, na.rm = TRUE)) %>%
  arrange(desc(Total_Corn))

# Summarize the total amount of placement corn given to each female
summary_female_corn <- BexClean %>%
  filter(!is.na(Female)) %>%
  group_by(Female) %>%
  summarise(Total_Corn = sum(PlacementFemale, na.rm = TRUE)) %>%
  arrange(desc(Total_Corn))

# Calculate means
mean_male_corn <- mean(summary_male_corn$Total_Corn)
mean_female_corn <- mean(summary_female_corn$Total_Corn)

# Custom colors for each Dyad
custom_colors <- scale_fill_manual(values = c(
  "Buk" = "#1f77b4", "Ndaw" = "#1f77b4",
  "Kom" = "#ff7f0e", "Oort" = "#ff7f0e",
  "Nge" = "#2ca02c", "Oerw" = "#2ca02c",
  "Pom" = "#d62728", "Xian" = "#d62728",
  "Sey" = "#9467bd", "Sirk" = "#9467bd",
  "Sho" = "#8c564b", "Ginq" = "#8c564b",
  "Xia" = "#e377c2", "Piep" = "#e377c2",
  "Xin" = "#7f7f7f", "Ouli" = "#7f7f7f"
))

# Plot for PlacementMale
plot_male_corn <- ggplot(summary_male_corn, aes(x = reorder(Male, -Total_Corn), y = Total_Corn, fill = Male)) +
  geom_bar(stat = "identity", width = 0.4) +
  geom_text(aes(label = Total_Corn), vjust = -0.5, size = 4) +
  geom_hline(yintercept = mean_male_corn, linetype = "dashed", color = "red") +
  annotate("text", x = Inf, y = mean_male_corn, label = paste("Mean:", round(mean_male_corn, 2)), hjust = 1.1, vjust = -0.5, color = "red") +
  labs(title = "Total Placement Corn Given to Males", x = "Male", y = "Total Placement Corn") +
  theme_minimal() +
  theme(legend.position = "none", text = element_text(size = 14), axis.text.x = element_text(angle = 45, hjust = 1)) +
  custom_colors

# Plot for PlacementFemale
plot_female_corn <- ggplot(summary_female_corn, aes(x = reorder(Female, -Total_Corn), y = Total_Corn, fill = Female)) +
  geom_bar(stat = "identity", width = 0.4) +
  geom_text(aes(label = Total_Corn), vjust = -0.5, size = 4) +
  geom_hline(yintercept = mean_female_corn, linetype = "dashed", color = "red") +
  annotate("text", x = Inf, y = mean_female_corn, label = paste("Mean:", round(mean_female_corn, 2)), hjust = 1.1, vjust = -0.5, color = "red") +
  labs(title = "Total Placement Corn Given to Females", x = "Female", y = "Total Placement Corn") +
  theme_minimal() +
  theme(legend.position = "none", text = element_text(size = 14), axis.text.x = element_text(angle = 45, hjust = 1)) +
  custom_colors

# Display the plots
print(plot_male_corn)
print(plot_female_corn)

```




### 3.8 DyadDistance - Creation of proximity
* I would like to create a variable called proximity to have another measure of the proximity of the individuals. 
* First lets look at the maximum and minimum distance found in Dyad Distance
```{r DyadDistance Max & Min, echo=FALSE}
# Find maximum distance
max_distance <- max(BexClean$DyadDistance, na.rm = TRUE)

# Find minimum distance
min_distance <- min(BexClean$DyadDistance, na.rm = TRUE)

# Print the results
cat("Maximum Distance:", max_distance, "\n")
cat("Minimum Distance:", min_distance, "\n")

```
* The **minumum Distance** is **0m** while the **maximum Distance** is **10m**
* Then lets make a graph of the frequency for each distances with a line for the median to show the most frquent distance
```{r DyadDistance Frequency, echo=FALSE}
# Calculate the frequency of each distance across all dyads
distance_freq <- BexClean %>%
  ungroup() %>%  # Ensure data is ungrouped before counting
  count(DyadDistance) %>%
  arrange(DyadDistance)

# Create the table
distance_freq_table <- distance_freq %>%
  rename(Frequency = n)

# Display the table
distance_freq_table

```


```{r DyadDistance Frequency Plot, echo=FALSE}


# Calculate the frequency of each distance across all dyads
distance_freq <- BexClean %>%
  ungroup() %>%  # Ensure data is ungrouped before counting
  count(DyadDistance) %>%
  arrange(DyadDistance)

# Create the horizontal bar plot with light purple bars
plot_distance_freq <- ggplot(distance_freq, aes(x = n, y = factor(DyadDistance))) +
  geom_bar(stat = "identity", fill = "#DDA0DD") +
  geom_text(aes(label = n), hjust = -0.2, size = 5, color = "black", position = position_nudge(x = 10)) +
  labs(title = "Frequency of Distances Between Boxes Across Every Dyad",
       y = "Dyad Distance (m)", x = "Frequency (Amount Trials)") +
  theme_minimal() +
  theme(
    text = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12, angle = 0, hjust = 1),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14)
  )

# Display the plot
print(plot_distance_freq)


```




* Now lets create a new variable called **Proximity** using the distances found in **DyadDistance** on the following model:
  a. 0 = Contact
  b. 1 - 2 = 1-2
  c. 2 - 3 = 2-3
  d. 4 - 5 = 4-5
  e. 5 - 10 = +5
  
```{r Proximity, echo=FALSE}
# Create the Proximity variable
BexClean <- BexClean %>%
  mutate(
    Proximity = case_when(
      DyadDistance == 0 ~ "Contact",
      between(DyadDistance, 1, 2) ~ "1-2",
      between(DyadDistance, 2, 3) ~ "2-3",
      between(DyadDistance, 4, 5) ~ "4-5",
      between(DyadDistance, 6, 10) ~ "5+",
      TRUE ~ NA_character_
    )
  )

```


```{r Proximity plot, echo=FALSE}

# Calculate frequency of each proximity category
proximity_freq <- BexClean %>%
  ungroup() %>%  # Ensure data is ungrouped before counting
  count(Proximity) %>%
  arrange(desc(n))

# Define light orange colors for the proximity categories
proximity_colors <- c("Contact" = "#FFD580", "1-2" = "#FFC966", "2-3" = "#FFBF40", "4-5" = "#FFB31A", "5+" = "#FFA500")

# Create the horizontal bar plot for Proximity
plot_proximity_freq <- ggplot(proximity_freq, aes(x = n, y = factor(Proximity, levels = c("Contact", "1-2", "2-3", "4-5", "5+")), fill = Proximity)) +
  geom_bar(stat = "identity", width = 0.4) +
  geom_text(aes(label = n), hjust = -0.2, size = 4, color = "black") +
  scale_fill_manual(values = proximity_colors) +
  labs(title = "Frequency of Proximity Categories",
       y = "Proximity (Meters)", x = "Frequency (Amount Trials)") +
  theme_minimal() +
  theme(
    legend.position = "none",
    text = element_text(size = 14),
    axis.text.y = element_text(angle = 0, hjust = 1),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14)
  )



# Display the plot
print(plot_proximity_freq)

```



# UPDATES FROM HERE

### 3.9.1 Dyad Response - Corrections and detailed cleaning

* Reminder: The different behaviors that are coded in **DyadResponse** are: **Distracted**, **Female aggress male**, **Male aggress female**, **Intrusion**, **Loosing interest**, **Not approaching**, **Tolerance** and **Other**
    * I will change the columns associated to each behavior (i.e. Response) of  **DyadResponse**  into dichotomic variables in order to see the frequency of each behaviour
    * This will allow me to see which behavior occurred more than others, and what differences are between dyads 
    * As multiple behaviours could occur within the same trial, multiple responses (data entries) can be found in a single cell. I will create a  hierarchy to reduce the amount of behaviors assigned to each trial (if  there is more than one).
      1. correct any potential discrepancies (ex. if tolerance and aggression occured within the same trial        aggression>tolerance)
      2. assign as few labels per trial, ideally one using a hierarchy among the occuring behaviours to            choose which response to keep
      3. get a better view and understanding of the data and the most common behaviours produced by each dyad       producing plots and tables
      4. if necessary create new variables that can complement redistribute the information initally found in       the column
      
* I will create some tables to have a better understanding of the state of the column dyadresponse and the different existing combinations at this point

* Also I will create the hierarchy before implementing in the dataset
    
### 3.9.2 Dyad Response description
  
* I need to know how many different combinations exist within DyadResponse and how many occurnces/cells have more than one response per cell. I need the code to not take in account the order but rather the responses in themselves
 * I want one table for the Different combinantions and one showing the differernt combinations for only ONE response per cell, in a second table
 
```{r DyadResponse MultipleResponse, echo=FALSE}
# Identify and display rows with multiple entries
beforesummaryrowswithmultipleentries <- which(sapply(BexClean$DyadResponse, function(x) length(unlist(strsplit(as.character(x), ";"))) > 1))

# Display the rows with multiple entries in DyadResponse
View(BexClean[beforesummaryrowswithmultipleentries, ])

# Print the number of rows with multiple entries and the total number of rows
cat("Number of rows with multiple entries in DyadResponse: ", length(beforesummaryrowswithmultipleentries), "\n")
cat("Rows with multiple entries in DyadResponse: ", beforesummaryrowswithmultipleentries, "\n")

# Add new column for Multiple Responses
BexClean$MultipleResponses <- ifelse(grepl(";", BexClean$DyadResponse), ">1 Response", "Single Response")

```  
  
```{r DyadResponse count of rows with single/multiple entries, echo=FALSE}

# Helper function to sort responses within each cell for consistency
sort_responses <- function(response) {
  sorted <- sapply(strsplit(response, ";"), function(x) paste(sort(trimws(x)), collapse = ";"))
  return(sorted)
}

# Apply the sorting function to the DyadResponse column
BexClean$DyadResponse_sorted <- sort_responses(BexClean$DyadResponse)

# Calculate the total number of rows in the dataset
total_rows <- nrow(BexClean)

# Calculate the number of rows with single and multiple responses
num_single_responses <- BexClean %>%
  filter(!grepl(";", DyadResponse)) %>%
  nrow()

num_multiple_responses <- BexClean %>%
  filter(grepl(";", DyadResponse)) %>%
  nrow()

# Print the counts and verify they add up to the total
cat("Total number of rows in DyadResponse: ", total_rows, "\n")
cat("Number of rows with a single entry in DyadResponse: ", num_single_responses, "\n")
cat("Number of rows with multiple entries in DyadResponse: ", num_multiple_responses, "\n")
cat("Sum of single and multiple entry rows: ", num_single_responses + num_multiple_responses, "\n")



```

```{r DyadResponse unique combinations and frequncies, echo=FALSE}

# Helper function to sort responses within each cell for consistency
sort_responses <- function(response) {
  sorted <- sapply(strsplit(response, ";"), function(x) paste(sort(trimws(x)), collapse = ";"))
  return(sorted)
}

# Apply the sorting function to the DyadResponse column
BexClean$DyadResponse_sorted <- sort_responses(BexClean$DyadResponse)

# Ensure data is ungrouped to focus only on unique combinations of responses
BexClean <- BexClean %>% ungroup()

# Identify unique combinations and their frequencies without Dyad and Day
unique_combinations <- BexClean %>%
  filter(grepl(";", DyadResponse_sorted)) %>%
  count(DyadResponse_sorted) %>%
  arrange(desc(n))

# Identify single and multiple responses
single_responses <- BexClean %>%
  filter(!grepl(";", DyadResponse_sorted)) %>%
  count(DyadResponse_sorted) %>%
  arrange(desc(n))

multiple_responses <- BexClean %>%
  filter(grepl(";", DyadResponse_sorted)) %>%
  count(DyadResponse_sorted) %>%
  arrange(desc(n))

# Display the results
cat("Unique combinations of multiple responses and their frequencies:\n")
print(unique_combinations)

cat("Rows with single responses in DyadResponse:\n")
print(single_responses)

cat("Rows with multiple responses in DyadResponse:\n")
print(multiple_responses)


```
  
  
  ### 3.9.3 Dyad Response Hierarchy 

* **Dyad Response Hierarchy** Projection of the hierarchy (changes will be made)
      - Aggression > Tolerance
      - Tolerance > Not approaching -> Create a variable called hesistant in         addtion to the tolerance count to see frequency of tolerance                 behaviour that happened after > 1min
      - Tolerance > Loosing interest
      - Tolerance > Intrusion      
      - Not approaching = looking box but not coming while Loosing interest           = not paying attention to the box
       - Intrusion > Loosing interest
      - Intrusion > Not approaching
      - Not approaching > Looks at partner
      - We can code every look at partner as no approaching and keep the             count of looks at partner as additional information       
      - Not approaching >?> Loosing interest ? !!
       - Define distracted
      - Not approaching > Distracted
      - Aggression > Not approaching
      - Other > Look case by case and categorize depending of behavior     
      - Remarks may be used for the same reason
        

  * First I want to see how many rows in DyadResponse have more than one entry per cell
  
    * And **if there are more than one value per cell**, report it in a new column called "MultipleResponses"


  
  
  



* Now that I know that they are 230 rows with multiple entries I will print each combinations to see which one I have to print and also display the combinations once the data is split. 
* I will make an intermediary summary to see that state of DyadResponse at the moment

* A. Summary od DyadResponse

* B.Idnetify Rows with more than 1 entry

*  Step 1: Identify Rows with More than 1 Entry
beforesummaryrowswithmultipleentries_1 <- which(sapply(BexClean$DyadResponse, function(x) length(unlist(strsplit(as.character(x), ";"))) > 1))

Display the rows with more than 1 entry in DyadResponse
knitr::kable(BexClean[beforesummaryrowswithmultipleentries_1, ])

* Print the amount of cells with more than 1 entry and the total number of rows
cat("Number of rows with more than 1 entry in DyadResponse: ", length(beforesummaryrowswithmultipleentries_1), "\n")

* C. Identify Rows with more than 2 entry
```{r DyadResponse > 2 entry, echo=FALSE}
# Step 1: Identify Rows with More than 1 Entry
beforesummaryrowswithmultipleentries_1 <- which(sapply(BexClean$DyadResponse, function(x) length(unlist(strsplit(as.character(x), ";"))) > 1))

# Print the amount of cells with more than 1 entry and the total number of rows
cat("Number of rows with more than 1 entry in DyadResponse: ", length(beforesummaryrowswithmultipleentries_1), "\n")

```
* D. 
```{r ,echo=FALSE}
# Step 3: Extract Unique Combinations for More than 1 Entry
all_combinations_1 <- unlist(lapply(beforesummaryrowswithmultipleentries_1, function(row) {
  unique_chars <- unlist(strsplit(as.character(BexClean$DyadResponse[row]), ";"))
  combn(unique_chars, 2, FUN = function(x) paste(x, collapse = " & "))
}))

# Step 4: Count Occurrences of Unique Combinations for More than 1 Entry
combination_counts_1 <- table(all_combinations_1)

# Display Unique Combinations and Counts for More than 1 Entry
cat("Unique Combinations and Counts for More than 1 Entry:\n")
for (entry in names(combination_counts_1)) {
  cat(sprintf("%-25s %d\n", entry, combination_counts_1[[entry]]))
  
after_summary4 <- nrow(BexClean)}

# Display the change in occurrences
cat("Change in Occurrences for the Chunk (Female aggress male > Not approaching): ", after_summary4 - beforesummary, "\n")
```


 6. Male agress female > Not approaching : Remove Not approaching if there is Male aggress female (2x)
```{r Male agress female > Intrusion, echo=FALSE}
# Count occurrences before modifications
beforesummary <- nrow(BexClean)
# 6. Remove rows with 'Not approaching' if 'Male aggress female' is present
BexClean <- BexClean[!(grepl("Not approaching", BexClean$DyadResponse) & grepl("Male aggress female", BexClean$DyadResponse)), ]

# Count occurrences after modification
after_summary6 <- nrow(BexClean)

# Display the change in occurrences
cat("Change in Occurrences for the Chunk (Male aggress female > Not approaching): ", after_summary6 - beforesummary, "\n")
```

 7. Tolerance > Distracted: Remove Distracted if there is tolerance (3x)

```{r Tolerance > Distracted, echo=FALSE}

# Count occurrences before modifications
beforesummary <- nrow(BexClean)

# Tolerance & Distracted: 7.Remove Distracted if there is tolerance
BexClean <- BexClean[!(grepl("Tolerance", BexClean$DyadResponse) & grepl("Distracted", BexClean$DyadResponse)), ]

# Count occurrences after modification
after_summary7 <- nrow(BexClean)

# Display the change in occurrences
cat("Change in Occurrences for the Chunk Tolerance > Distracted: ", after_summary7 - beforesummary, "\n")

```

8.Female agress male > Tolerance: Remove Tolerance if there is Female agress male (23x)
 
```{r Female agress male > Tolerance, echo=FALSE}
# Count occurrences before modifications
beforesummary <- nrow(BexClean)

# 8. Remove rows with 'Tolerance' if 'Female aggress male' is present
BexClean <- BexClean[!(grepl("Tolerance", BexClean$DyadResponse) & grepl("Female aggress male", BexClean$DyadResponse)), ]

# Count occurrences after modification
after_summary8 <- nrow(BexClean)

# Display the change in occurrences
cat("Change in Occurrences for the Chunk (Tolerance & Female aggress male): ", after_summary8 - beforesummary, "\n")

```



 9.Tolerance > Loosing interest: Remove Losing interest if there is Tolerance (13x)
```{r Tolerance > Loosing interest, echo=FALSE}
# Count occurrences before modifications
beforesummary <- nrow(BexClean)

# Count occurrences after modification
after_summary9 <- nrow(BexClean)

# Display the change in occurrences
cat("Change in Occurrences for the Chunk (Tolerance & Losing interest): ", after_summary9 - beforesummary, "\n")


```
 10.Male agress female > Tolerance : Remove Tolerance if there is Male agress male (31)
```{r Male agress female > Tolerance, echo=FALSE}
 # Count occurrences before modifications
beforesummary <- nrow(BexClean)

# 10. Remove rows with 'Tolerance' if 'Male aggress female' is present
BexClean <- BexClean[!(grepl("Tolerance", BexClean$DyadResponse) & grepl("Male aggress female", BexClean$DyadResponse)), ]

# Count occurrences after modification
after_summary10 <- nrow(BexClean)

# Display the change in occurrences
cat("Change in Occurrences for the Chunk (Tolerance & Male aggress female): ", after_summary10 - beforesummary, "\n")

```
 11.Tolerance > Not approaching: Remove Not approaching if there is tolerance (6x)
```{r Tolerance > Not approaching, echo=FALSE}
# Count occurrences before modifications
beforesummary <- nrow(BexClean)

# 11. Remove rows with 'Not approaching' if 'Tolerance' is present
BexClean <- BexClean[!(grepl("Not approaching", BexClean$DyadResponse) & grepl("Tolerance", BexClean$DyadResponse)), ]


# Count occurrences after modification
after_summary11 <- nrow(BexClean)

# Display the change in occurrences
cat("Change in Occurrences for teh Chunk (Tolerance & Not approaching): ", after_summary11 - beforesummary, "\n")
```

* Looks at partner &  Other 1                  - Display line for detailed check (1x)
 * Not approaching &  Losing interest 46        - Keep both, I will consider doing a detailled check
 * Not approaching &  Distracted 7              - Display line for detailed check
 * Not approaching &  Other  1                  - Display line for detailed check
 * Tolerance &  Other        8                  - Display line for detailed check


SEE WHEN AND HOW TO Put ThIS CODE TO REPLACE PREIVOSU NUMBERS:


# 1. Aggression > Tolerance
BexClean <- BexClean[!(grepl("Tolerance", BexClean$DyadResponse) & (grepl("Female aggress male", BexClean$DyadResponse) | grepl("Male aggress female", BexClean$DyadResponse))), ]

# 2. Tolerance > Not approaching
BexClean <- BexClean[!(grepl("Not approaching", BexClean$DyadResponse) & grepl("Tolerance", BexClean$DyadResponse)), ]

# 3. Tolerance > Loosing interest
BexClean <- BexClean[!(grepl("Losing interest", BexClean$DyadResponse) & grepl("Tolerance", BexClean$DyadResponse)), ]

# 4. Tolerance > Intrusion
BexClean <- BexClean[!(grepl("Intrusion", BexClean$DyadResponse) & grepl("Tolerance", BexClean$DyadResponse)), ]

# 5. Intrusion > Loosing interest
BexClean <- BexClean[!(grepl("Losing interest", BexClean$DyadResponse) & grepl("Intrusion", BexClean$DyadResponse)), ]

# 6. Intrusion > Not approaching
BexClean <- BexClean[!(grepl("Not approaching", BexClean$DyadResponse) & grepl("Intrusion", BexClean$DyadResponse)), ]

# 7. Not approaching > Looks at partner
# Code every look at partner as not approaching and keep the count of looks at partner as additional information

# 8. Define distracted
# Not approaching > Distracted
BexClean <- BexClean[!(grepl("Distracted", BexClean$DyadResponse) & grepl("Not approaching", BexClean$DyadResponse)), ]

# 9. Other > Look case by case and categorize depending on behavior

# Final clean-up and reporting
knitr::kable(BexClean, col.names = colnames(BexClean), caption = "Cleaned DyadResponse Data")

* Code to display rows numbers and the response in DyadResponse that have mroe than one entry



* Other Reponse - DEtailed cleaning to delete the column
* Audience - Creation of Amount Audience and Density
* ID Individua1 - Not sure yet
* Intruder ID 
* Remarks - Detailed Cleaning
* Intrusion
* Not Approaching
* Lossing Interest
* Distracted
* MultipleResponse
* Amount Audience
* DyadDistance
* Distance
* No trial


#### Code to keep and place again
# Code to settle 

I also chose to directly create new dichotomic variables for "Not approaching", "Intrusion", "Losing interest", "Distracted", for this I would like the function to
  1.Check if there is a **value different than "No individual"**
  2.**If the value ≠"No individual"** then I want it to **take the response found in "DyadResposne"** 

```{r Create dichotomous variables, echo=FALSE}
# Check if the "MultipleResponses" column already exists
if (!"MultipleResponses" %in% names(BexClean)) {
  # Replace NA in IDIndividual1 by "No individual"
  BexClean$IDIndividual1[is.na(BexClean$IDIndividual1)] <- "No individual"

  # Check for multiple responses
  BexClean$MultipleResponses <- ifelse(
  BexClean$IDIndividual1 != "No individual" & grepl("[;,] ?", BexClean$DyadResponse),
  ">1 Response",
  "Single Response"
)

  
  View(BexClean)
} else {
  cat("The 'MultipleResponses' column already exists. No changes made.\n")
}
```

```{r Check Responses in DyadResponse for Id1, echo=FALSE}
# Count occurrences of each behavior in DyadResponse
count_NotApproaching <- sum(grepl("Not approaching", BexClean$DyadResponse))
count_Intrusion <- sum(grepl("Intrusion", BexClean$DyadResponse))
count_LosingInterest <- sum(grepl("Losing interest", BexClean$DyadResponse))
count_Distracted <- sum(grepl("Distracted", BexClean$DyadResponse))

cat("Occurrences of 'Not approaching' in DyadResponse:", count_NotApproaching, "\n")
cat("Occurrences of 'Intrusion' in DyadResponse:", count_Intrusion, "\n")
cat("Occurrences of 'Losing interest' in DyadResponse:", count_LosingInterest, "\n")
cat("Occurrences of 'Distracted' in DyadResponse:", count_Distracted, "\n")


# Count the number of '1's in the new variables
count_NotApproaching_1 <- sum(BexClean$NotApproaching == 1)
count_Intrusion_1 <- sum(BexClean$Intrusion == 1)
count_LosingInterest_1 <- sum(BexClean$LosingInterest == 1)
count_Distracted_1 <- sum(BexClean$Distracted == 1)

cat("Occurrences of '1' in 'NotApproaching':", count_NotApproaching_1, "\n")
cat("Occurrences of '1' in 'Intrusion':", count_Intrusion_1, "\n")
cat("Occurrences of '1' in 'LosingInterest':", count_LosingInterest_1, "\n")
cat("Occurrences of '1' in 'Distracted':", count_Distracted_1, "\n")

```



### Exploratory Graph (To organise)

####Dyad, Distance & Date

* Trials of grpahs, I will have to check all of them

* My goal here is too see if each dyad have an general evolution of their dyad distance trough time and how many varaition do they have

```{r Dyad Distance & Date, echo=FALSE}
# Load required libraries
library(ggplot2)
library(dplyr)
library(lubridate)

# Check if the DyadDistance column exists
if("DyadDistance" %in% colnames(BexClean)) {
    # Convert Date column to Date format if it's not already
    BexClean$Date <- as.Date(BexClean$Date)

    # Plot using Date
    plot <- ggplot(data = BexClean, aes(x = Date, y = DyadDistance, group = Dyad, color = Dyad)) +
      geom_smooth(se = FALSE, method = "loess") +
      theme_minimal() +
      labs(x = "Date", y = "Dyad Distance", title = "Dyad Distance Over Time", color = "Dyad")

    # Print the plot
    print(plot)
} else {
    print("DyadDistance column not found in BexClean dataframe")
}


```


```{r Other graphs, echo=FALSE}


# Load required libraries
library(ggplot2)
library(dplyr)

# Ensure Date is in the correct format
BexClean$Date <- as.Date(BexClean$Date)

# Plot with smoothed lines and confidence intervals with improved readability
daily_plot <- ggplot(data = BexClean, aes(x = Date, y = DyadDistance, group = Dyad, color = Dyad)) +
  geom_smooth(method = "loess", se = TRUE, alpha = 0.2, size = 1) + # Adjusted alpha and line size
  theme_minimal() +
  theme(legend.position = "right") + # Adjust legend position
  labs(x = "Date", y = "Dyad Distance", title = "Dyad Distance Over Time with Confidence Interval", color = "Dyad") +
  expand_limits(y = c(0, NA)) # Expand y-axis limits if needed

# Print the daily plot
print(daily_plot)

                    
```

```{r daily graph, echo=FALSE}
library(ggplot2)
library(dplyr)
library(lubridate)

# Ensure Date is in the correct format
BexClean$Date <- as.Date(BexClean$Date)

# Aggregate data by month and calculate mean and SD
monthly_stats <- BexClean %>%
  mutate(Month = floor_date(Date, "month")) %>%
  group_by(Dyad, Month) %>%
  summarise(
    Mean_DyadDistance = mean(DyadDistance, na.rm = TRUE),
    SD_DyadDistance = sd(DyadDistance, na.rm = TRUE)
  )

# Faceted plot with Mean Points and Error Bars for each month
faceted_monthly_plot <- ggplot(data = monthly_stats, aes(x = Month, y = Mean_DyadDistance, color = Dyad)) +
  geom_point(size = 2) +
  geom_errorbar(aes(y))
```

```{r Monthly graph, echo=FALSE}
# Load required libraries
library(ggplot2)
library(dplyr)
library(lubridate)

# Ensure Date is in the correct format
BexClean$Date <- as.Date(BexClean$Date)

# Aggregate data by month and calculate mean and SD
monthly_stats <- BexClean %>%
  mutate(Month = floor_date(Date, "month")) %>%
  group_by(Dyad, Month) %>%
  summarise(
    Mean_DyadDistance = mean(DyadDistance, na.rm = TRUE),
    SD_DyadDistance = sd(DyadDistance, na.rm = TRUE),
    .groups = 'drop' # This will remove the grouping after summarisation
  )

# Faceted plot with Mean Points and Error Bars for each month
faceted_monthly_plot <- ggplot(data = monthly_stats, aes(x = Month, y = Mean_DyadDistance, color = Dyad)) +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = Mean_DyadDistance - SD_DyadDistance, ymax = Mean_DyadDistance + SD_DyadDistance), width = 0.2) +
  facet_wrap(~ Dyad, scales = 'free_y') + # Faceting by Dyad, with free y scales for each facet
  theme_minimal() +
  labs(x = "Month", y = "Mean Dyad Distance", title = "Monthly Mean Dyad Distance with SD by Dyad", color = "Dyad")

# Print the faceted monthly plot
print(faceted_monthly_plot)
```

```{r last test before sleep, echo=FALSE}

library(ggplot2)
library(dplyr)
library(lubridate)

# Ensure Date is in the correct format
BexClean$Date <- as.Date(BexClean$Date)

# Aggregate data by month and calculate mean and SD
monthly_stats <- BexClean %>%
  mutate(Month = floor_date(Date, "month")) %>%
  group_by(Dyad, Month) %>%
  summarise(
    Mean_DyadDistance = mean(DyadDistance, na.rm = TRUE),
    SD_DyadDistance = sd(DyadDistance, na.rm = TRUE),
    .groups = 'drop'
  )

# Calculate the grand mean DyadDistance for each Dyad
grand_means <- monthly_stats %>%
  group_by(Dyad) %>%
  summarise(Grand_Mean_DyadDistance = mean(Mean_DyadDistance, na.rm = TRUE))

# Faceted plot with Mean Points, Error Bars, Lines for each month, and Grand Mean Line
faceted_monthly_plot_with_lines <- ggplot(data = monthly_stats, aes(x = Month, y = Mean_DyadDistance, color = Dyad, group = Dyad)) +
  geom_line() +
  geom_point(size = 2) +
  geom_errorbar(aes(ymin = Mean_DyadDistance - SD_DyadDistance, ymax = Mean_DyadDistance + SD_DyadDistance), width = 0.2) +
  geom_hline(data = grand_means, aes(yintercept = Grand_Mean_DyadDistance, color = Dyad), linetype = "dashed") +
  facet_wrap(~ Dyad) + # Removed scales = 'free_y' for a uniform scale
  theme_minimal() +
  labs(x = "Month", y = "Mean Dyad Distance", title = "Monthly Mean Dyad Distance with SD by Dyad", color = "Dyad")

# Print the faceted monthly plot with lines and grand mean
print(faceted_monthly_plot_with_lines)

```


```{r daily graph2, echo=FALSE}
library(ggplot2)
library(dplyr)
library(lubridate)

# Ensure Date is in the correct format
BexClean$Date <- as.Date(BexClean$Date)

# Aggregate data by month and calculate mean and SD
monthly_stats <- BexClean %>%
  mutate(Month = floor_date(Date, "month")) %>%
  group_by(Dyad, Month) %>%
  summarise(
    Mean_DyadDistance = mean(DyadDistance, na.rm = TRUE),
    SD_DyadDistance = sd(DyadDistance, na.rm = TRUE),
    .groups = 'drop' # Avoid regrouping after summarise
  )

# Calculate overall mean and standard deviation for reference
overall_mean <- mean(BexClean$DyadDistance, na.rm = TRUE)
overall_sd <- sd(BexClean$DyadDistance, na.rm = TRUE)

# Faceted plot with Mean Points and Error Bars for each month
faceted_monthly_plot <- ggplot(data = monthly_stats, aes(x = Month, y = Mean_DyadDistance, color = Dyad)) +
  geom_point(size = 3) + # Slightly larger points for visibility
  geom_errorbar(aes(ymin = Mean_DyadDistance - SD_DyadDistance, ymax = Mean_DyadDistance + SD_DyadDistance), width = 0.2) +
  geom_hline(yintercept = overall_mean, linetype = "dashed", color = "red") + # Line for overall mean
  geom_ribbon(aes(ymin = overall_mean - overall_sd, ymax = overall_mean + overall_sd), fill = "red", alpha = 0.2) + # Shaded area for overall SD
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) + # Rotate x labels for better readability
  labs(x = "Month", y = "Mean Dyad Distance", title = "Monthly Mean Dyad Distance by Dyad", color = "Dyad")

# Print the faceted monthly plot
print(faceted_monthly_plot)

```
  
   * I want to use the date to know **how many sessions** have been done with each dyads in my experiment. 
    * I will create a variable called **Session** where **1 session = 1 day**
    * The data has values from the **14th of September 2022** until the **13th of September 2023**
    * I will also create a variable called **Trial** to know how many trials have been done with each dyad where **1 row = 1 trial** 
    
    * I may consider, in parallel of my hypothesis, to separate the data in *4 seasons* to make a preliminary check of a potential effect of seasonality. Nevertheless the fact that we did not use anywithout      tools to mesure the weather and the idea to make a categorization in 4 seasons without considering the actua quite arbitrary. I may do it but with no intention to include this in my scientific report.
    l temperature, food quantitiy and other elements related to seasonailty make this categorizationn a categorization where 12 months of          data will be separated in 4 categories
   


* But before I may want to make a few changes already by merging **Male corn** and **Male placement corn** into " Male corn" and maybe replacing all of the NA's in "Other response" by response

#Lines to check unique values in MaleFemaleID to see if they are any problems with it
# Unique values in MaleID
unique_male_ids <- unique(BexClean$MaleID)

# Unique values in FemaleID
unique_female_ids <- unique(Bex$FemaleID)









# Sections below are here for the organization of my paper and will be worked on once the data cleaning and exploration is done

## 3. Describing the data

## 4.Visualizing the data

## 5.Research question & Hypothesis

### Research question

-   What factors influence the rate at which individuals (vervets) learn
    to tolerate each other in a controlled box experiment?

-   Ex: The rate at which individuals (vervets) learn to tolerate each
    other in a box experiment is influenced by social factors (audience,
    social network, behavior of the partner) and idioyncratic factors
    (age, rank)

### Hypothesis

-   1.  Hypothesis about the Presence of High-Ranking Individuals:

The presence of a higher number of high-ranking individuals in the
audience will negatively correlate with the level of tolerance achieved
among vervets in the box experiment. This is expected to result in
higher frequencies of aggressive behaviors, intrusions, and loss of
interest, particularly from lower-ranking individuals.

-   2.  Hypothesis about Partner Agonistic Behaviors:

Vervets tolerance levels in the box experiment will be influenced by
their partner’s display of agonistic behaviors. Specifically, partners
who exhibit more frequent agonistic behaviors towards their partner will
lead to decrease in their motivation to participate in future trials.

-   3.  Hypothesis about the Establishment of an Optimal Distance:

During the box experiment, vervet dyads will establish an “optimal”
distance for interaction, characterized by a higher frequency of
tolerance compared to other distances. This optimal distance is expected
to signify that the individuals tolerate each other more effectively at
this specific proximity .

-   4.  Hypothesis about Age and Rank:

The age and rank of individual vervets within the group will influence
the success of the trials in the box experiment. Specifically, older and
higher-ranking individuals are expected to exhibit lower rates of
success compared to dyads consisting of younger and lower-ranked
individuals. This decrease in success is anticipated to be associated
with a higher frequency of aggressive behaviors displayed by older and
higher-ranking individuals towards their partners. (I’m not sure this
hypothesis makes sens, I have the feeling age and rank must have an
influence but I don’t know how to put it, I will think about it)

-   5.  Hyptohesis about seasonality

Seasonality is expected to impact the motivation of vervet dyads to
participate in the box experiment. We hypothesize that dyads will have
lower motivation, as indicated by a reduced number of trials, during the
summer months compared to the winter months. This difference in
motivation is likely influenced by temperature and food availability. To
test this hypothesis, we will categorize the data into four seasonal
periods, each spanning four months, and analyze whether there is a
significant effect of seasonality on the motivation to engage in the
trials.

## 6.Statistical tests and analisis of the data

### Statistical tests

-   **Hypothesis 1**: Influence of High-Ranking Individuals

Variables Needed:

**DyadResponse** (specifically, “aggression” responses)
**Amountaudience** (to measure the number of individuals in the
audience) **Audience…15** (to identify the names of individuals in the
audience for calculating dominance ranks) **Elo rating** of the
individuals based on the ab libitum data collected in IVP (which I have
to calculate asap)

Statistical Analysis:**Logistic Regression**, as it could analyze the
influence of high-ranking individuals on the occurrence of aggression in
dyad responses. This will help determine whether the presence of
high-ranking individuals affects the likelihood of aggression.

-   **Hypothesis 2**: Impact of Partner’s Agonistic Behaviors

Variables Needed:

-   **DyadResponse** (specifically, “aggression” responses)
-   **MaleagressF** (male’s aggression towards female)
-   **FemaleaggressM** (female’s aggression towards male)

Statistical Analysis: **Logistic Regression** as it could be used to
assess how the occurrence of aggression in dyad responses is influenced
by the partner’s gender-specific agonistic behaviors.

-   **Hypothesis 3**: Identification of an Optimal Interaction Distance

Variables Needed:

-   **DyadDistance** (distance between boxes)
-   **Tolerance** (as a binary outcome)

Statistical Analysis: **generalized Linear Model (GLM)** to investigate
whether there is an optimal distance that leads to a higher likelihood
of tolerance (Tolerance = 1).

-   **Hypothesis 4**: Role of Age and Rank

Variables Needed:

-   **Tolerance** (as a binary outcome)
-   **Male and Female** (to identify individuals’ ages and ranks)
-   **Dyad** (to link individuals to dyads)
-   **Birthdate** to calculate the age of each individual

Statistical Analysis: **Logistic Regression** Logistic regression can be
employed to determine whether the age and rank of individual vervets
within dyads have an impact on the likelihood of tolerance (Tolerance =
1).

-   **Hypothesis 5**: Influence of Seasonality

Variables Needed:

-   **Date** (to categorize data into seasons)
-   **Trial** (to count the number of trials in each season) and the
    data for at least 365 days so i can separate the data in 4 (1 year =
    4 seasons = 12\*4 month) to see if they may be an effect of
    seasonality on the motivation (amount of trials) of the dyads

Statistical Analysis:

ANOVA or Kruskal-Wallis Test: Depending on the distribution of your
trial data, you can use either ANOVA (if the data are normally
distributed) or the Kruskal-Wallis test (for non-normally distributed
data) to assess the impact of seasonality on the number of trials. If
significant differences are found, you can follow up with post-hoc tests
to identify which seasons differ from each other. Please note that the
effectiveness of these analyses may depend on the distribution of your
data and specific research objectives. You may also consider conducting
exploratory data analysis (e.g., visualization) to gain a better
understanding of your dataset before performing these analyses.
Additionally, if you have specific questions about data preprocessing or
variable transformations, feel free to ask for further guidance. –> I
took this from ChatGPT, I have to look more into it

**REMARKS**: So here are a few updates I made in the document. I also
planned to send my cleaned data to Radu (the statistician of UNINE) as
he was keen to help me find the right test. Of course I will also look
again in Bshary’s and Charlotte’s work with the boxes and improve these
suggestions that are quite simple for now

Also I still have to clean the last grpahs about male/female aggression
as I didn’t finish that yet. I juste wanted to share my hypothesis and
ideas for statistics so I can soon go into the “serious” work

Anyway, thank you in advance for your help \<3

Michael

## 7. Plotting the results of the analysis

## 9. Interpretation of the results

## 10. Comeback on the research question and hypothesis

## 11. Bibliography

## 12. Organization for my paper

-   Introduction
    -   Tolerance humans, primates
    -   Apes vs monkeys / Captivity vs Wild
    -   IVP: Wild habituated vervets, experiments possible
    -   Paper Bshary, Canteloup… Prolongation study
    -   Relevance idea/topic research
    -   Research question & hypothesis

But: intro need triangle shape: broad to narrow end wiht research
question> tolerance importance \> animal reign, actual knowledge/
direction knowledge we need \> show how my experiment goes in that way
How to adress the gap, answer with research question

Then explain why choosing vervet monkeys, (IVP in methods), sociality,
experiments made

-   Methods

    -   IVP, research area, (goal, house, type people)

    -   Population: groups, dyads, male/female, ranks..

    -   Box material: boxes, remotes, batteries, camera, tripod, corn
        (no marmelade ;), (water spray, security reason, non agressive
        way to select individuals and not engage with mokeys when
        reachrging boxes with corn), pattern, previous distances,
        tablets, box experiment form

    -   Tablets

    -   (No observers mentionned)

    -   Habituation boxes > individuals trained to recognice boxes, they
        have differernt levels of habituation

    -   Patterns > appendix, mention similar to habituation, use to
        recognize box but efficieny depeds of experience)

    -   Selection dyads > assigment from elo rating (different rank), if
        above average bond no dyad made, if not possible, availibilty of
        monkey also factor !! Non random can be a problem, think about
        why and how you selected data We created variations in dyads
        made by different sex, rank and not above average bonde
        (calculate bondeness)

    -   Amount corn, do you want to mention it> maybe important
        Calculate corn during and placement cf paper on corn /food
        motivation

    -   Corn (daily intake vervet % made from corn, cf site we saw, cf
        screenshot, comapre paper previousely made an all)

    -   1st dyad trial (BD) > appendix

    -   Videos > details appendix

    -   Finding dyads > appendix

    -   Placement to attract them > meniton if statiscial made on
        placement corn

    -   Trials (1 session = max 15 trials/in total) (session could be
        broken in different sub sessions to reach 15 trials max)

    -   If agression > 1m / If 2x tolerance \< 1m , also if not
        approaching > 1m ( if no tolerance increase distance except if
        intrusion) (borgeaud > expectation fo aggression)

    -   Time of the day > appendix

    -   Territory? > appendix

    -   Amount sessions p day/week, how we chose the moment to follow
        them >appendix

    -   Problems/ unplanned events: weather, BGE’s, not finding the
        monkeys (group, dyad or individual), dispersal of males, river
        crossing, inacessibility (experiments or boxes), low vision
        (experiments or monkeys),> appendix

    -   (Where do i mention the confounding variables?) > look in
        litterature, if something that could affect and already reported
        in papers check, oterhwise exclude “normal life” factors for
        both monekys and Experimenter

    -   Types of experimental plan

    -   Statistical tests (for each hypothesis)

-   Analysis

-   Results

-   Interpretation

-   Conclusion


#########

# Glossary
* **Tolerance**: Tolerance: An individual has an encounter with a conspecific and
  can freely leave but remains in the encounter without acting aggressively
  toward the conspecific. (Pisor & Surbeck, 2019)
* **Agression**
* **Session** 
* **Trial**
* **Group**: In the Primate order, groups are individuals “which remain [physically] together in or separate from a larger unit” and interact with each other more than with other individuals.6 This            definition does not cover all uses of the word “group” in the social sciences (e.g., human identity groups who identify with a common name or symbol may or may not interact with one another more frequently   than with other individuals). Because of this ambiguity, we use the word “community” when referring to humans to better capture the notion of spatial proximity, per Ref. 54. Members of the same group are    referred to as “same-group” and those from another group “extra-group.” (Pisor & Surbeck, 2019)


# Bibliography
 • Pisor, A. C., & Surbeck, M. (2019). The evolution of intergroup tolerance in nonhuman primates and humans. Evolutionary Anthropology: Issues and ReViews. Advance online publication. https://doi.org/10.1002/evan.21793
(Pisor & Surbeck, 2019)


# Annex

#### Annex 1 : View of the dataset when imported - First 6 entries of each variable 
* We can see here the brief View of the **original dataset** names **BoxEx**when i initially imported it as seen in **section 0: Opening data** 



```{r View of the data Boxex, echo=FALSE}

# Display the original dataset that is name Boxex
pander(head(Boxex), style = "rmarkdown", caption = "First Few Entries") 

```
```beforeNA